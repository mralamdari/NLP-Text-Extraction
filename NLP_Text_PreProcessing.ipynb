{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-Text-PreProcessing.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Wq31EKDPV0f_",
        "TYPEaAgXV-EN",
        "0mOPQn0DWFdD"
      ],
      "authorship_tag": "ABX9TyNmEdV35GKKxVA0DEPNlFdm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/NLP-Text-Processing/blob/main/NLP_Text_PreProcessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GD6K9gKUjIOy"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "import spacy\n",
        "import string\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_original = \"Need to finalize the demo corpus which will be used for this notebook and it should be done soon !!. It should be done by the ending of this month. But will it? This notebook has been run 4 times !!\"\n",
        "corpus = \"Need to finalize the demo corpus which will be used for this notebook & should be done soon !!. It should be done by the ending of this month. But will it? This notebook has been run 4 times !!\""
      ],
      "metadata": {
        "id": "lUrdtzgOoeHL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = re.sub(r'\\d+', '', corpus.lower())"
      ],
      "metadata": {
        "id": "SGHk8_EVogwC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "y4HoUeAZ2Z9S",
        "outputId": "cd696740-3226-4c90-844f-208bcf3ebb51"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'need to finalize the demo corpus which will be used for this notebook & should be done soon !!. it should be done by the ending of this month. but will it? this notebook has been run  times !!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = corpus.translate(str.maketrans('', '', string.punctuation))"
      ],
      "metadata": {
        "id": "8UIoZi_H5mJh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(string.punctuation)\n",
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "fXYooP_f53ZM",
        "outputId": "3d14ce5f-cbb5-4e60-b10e-c3730126223d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'need to finalize the demo corpus which will be used for this notebook should be done soon it should be done by the ending of this month but will it this notebook has been run times'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = ' '.join([token for token in corpus.split()])"
      ],
      "metadata": {
        "id": "A_FGtycN54l0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "rZdDWisl7RIx",
        "outputId": "4a0570c0-0955-43a8-e355-80f4b48cf04c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'need to finalize the demo corpus which will be used for this notebook should be done soon it should be done by the ending of this month but will it this notebook has been run times'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm\n",
        "spacy_model = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJB40W7A7RUl",
        "outputId": "80015429-9c89-4d06-ea47-f064f36be39d"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.7)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.9.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.64.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.10.8)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tokenize the Text"
      ],
      "metadata": {
        "id": "7Qe5dDXaVTOP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Stop Words"
      ],
      "metadata": {
        "id": "Wq31EKDPV0f_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Stop Words with NLTK"
      ],
      "metadata": {
        "id": "TYPEaAgXV-EN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "GslfQw877VxV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba13437a-ab38-49e6-ce91-d8cb2db5a999"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words_nltk = set(nltk.corpus.stopwords.words('english'))\n",
        "len(stop_words_nltk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tbqzRAmVf1j",
        "outputId": "fad0e245-85cf-4bbd-e013-95c18dd28e56"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_corpus_nltk = nltk.tokenize.word_tokenize(corpus)\n",
        "print(len(tokenized_corpus_nltk))\n",
        "tokenized_corpus_nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IT9D0XmnVoxx",
        "outputId": "c0fe94ae-1fac-4c9b-a046-4f1747861828"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['need',\n",
              " 'to',\n",
              " 'finalize',\n",
              " 'the',\n",
              " 'demo',\n",
              " 'corpus',\n",
              " 'which',\n",
              " 'will',\n",
              " 'be',\n",
              " 'used',\n",
              " 'for',\n",
              " 'this',\n",
              " 'notebook',\n",
              " 'should',\n",
              " 'be',\n",
              " 'done',\n",
              " 'soon',\n",
              " 'it',\n",
              " 'should',\n",
              " 'be',\n",
              " 'done',\n",
              " 'by',\n",
              " 'the',\n",
              " 'ending',\n",
              " 'of',\n",
              " 'this',\n",
              " 'month',\n",
              " 'but',\n",
              " 'will',\n",
              " 'it',\n",
              " 'this',\n",
              " 'notebook',\n",
              " 'has',\n",
              " 'been',\n",
              " 'run',\n",
              " 'times']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_words_without_stopwords_nltk = [i for i in tokenized_corpus_nltk if i not in stop_words_nltk] \n",
        "print(len(tokenized_words_without_stopwords_nltk))\n",
        "tokenized_words_without_stopwords_nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySc_d36KWchx",
        "outputId": "eb4d5cfc-bed5-4468-c54a-2f6e1a466780"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['need',\n",
              " 'finalize',\n",
              " 'demo',\n",
              " 'corpus',\n",
              " 'used',\n",
              " 'notebook',\n",
              " 'done',\n",
              " 'soon',\n",
              " 'done',\n",
              " 'ending',\n",
              " 'month',\n",
              " 'notebook',\n",
              " 'run',\n",
              " 'times']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Stop Words with Spacy"
      ],
      "metadata": {
        "id": "0mOPQn0DWFdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "spacy_model = spacy.load('en_core_web_sm')\n",
        "\n",
        "stop_words_sparcy = spacy_model.Defaults.stop_words\n",
        "len(stop_words_sparcy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0v-e12CVpwt",
        "outputId": "4d35f323-abb6-466a-f21b-652dbc888aa8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "326"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_corpus_sparcy = nltk.tokenize.word_tokenize(corpus)\n",
        "print(len(tokenized_corpus_sparcy))\n",
        "tokenized_corpus_sparcy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78E4HiAyXqK7",
        "outputId": "c522e388-7caf-4294-b640-819f3958a684"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['need',\n",
              " 'to',\n",
              " 'finalize',\n",
              " 'the',\n",
              " 'demo',\n",
              " 'corpus',\n",
              " 'which',\n",
              " 'will',\n",
              " 'be',\n",
              " 'used',\n",
              " 'for',\n",
              " 'this',\n",
              " 'notebook',\n",
              " 'should',\n",
              " 'be',\n",
              " 'done',\n",
              " 'soon',\n",
              " 'it',\n",
              " 'should',\n",
              " 'be',\n",
              " 'done',\n",
              " 'by',\n",
              " 'the',\n",
              " 'ending',\n",
              " 'of',\n",
              " 'this',\n",
              " 'month',\n",
              " 'but',\n",
              " 'will',\n",
              " 'it',\n",
              " 'this',\n",
              " 'notebook',\n",
              " 'has',\n",
              " 'been',\n",
              " 'run',\n",
              " 'times']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_words_without_stopwords_sparcy = [i for i in tokenized_corpus_sparcy if i not in stop_words_sparcy] \n",
        "print(len(tokenized_words_without_stopwords_sparcy))\n",
        "tokenized_words_without_stopwords_sparcy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yg9MuBakXhgf",
        "outputId": "889a72c9-d4d2-4d39-8512-472b1184a980"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['need',\n",
              " 'finalize',\n",
              " 'demo',\n",
              " 'corpus',\n",
              " 'notebook',\n",
              " 'soon',\n",
              " 'ending',\n",
              " 'month',\n",
              " 'notebook',\n",
              " 'run',\n",
              " 'times']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('The Difference between nltk and sparcy in stop words:\\n')\n",
        "set(tokenized_words_without_stopwords_nltk) - set(tokenized_words_without_stopwords_sparcy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBKvuJ6BXjGS",
        "outputId": "051e6ae6-a694-4e3b-b4d4-5798728a100e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Difference between nltk and sparcy in stop words:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'done', 'used'}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pyenchant\n",
        "import enchant\n",
        "from enchant import DictWithPWL\n",
        "from enchant.checker import SpellChecker\n",
        "\n",
        "my_dict = DictWithPWL(\"en_US\", \"mywords.txt\")\n",
        "my_checker = SpellChecker(my_dict)\n",
        "\n",
        "my_checker.set_text(\"This is sme sample txt with erors.\")\n",
        "for error in my_checker:\n",
        "    print (\"ERROR:\", error.word)"
      ],
      "metadata": {
        "id": "s663r3tuYbdz"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Lemmatization"
      ],
      "metadata": {
        "id": "4n3WpiEo55c6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0uYIS7D2ZFC",
        "outputId": "223ed053-dec2-48dd-9db7-86f0534b1d9d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in tokenized_words_without_stopwords_nltk:\n",
        "  print(lemmatizer.lemmatize(word), end=' ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSrNiBXU6eFC",
        "outputId": "aac3e544-3ef9-46bd-9c31-5c97f163c70c"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "need finalize demo corpus used notebook done soon done ending month notebook run time "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in tokenized_corpus_nltk:\n",
        "  print(lemmatizer.lemmatize(word), end=' ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0PWLK-564M-",
        "outputId": "84da2bb5-4b9e-4b1f-cac6-682ba530d33a"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "need to finalize the demo corpus which will be used for this notebook should be done soon it should be done by the ending of this month but will it this notebook ha been run time "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###POS Tagging"
      ],
      "metadata": {
        "id": "YPFHo1nE7y1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = spacy_model(corpus_original)"
      ],
      "metadata": {
        "id": "xsEjw8BO7mJ7"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  print(token, token.pos_, token.tag_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzwS1PGs8W_4",
        "outputId": "4108e2de-da41-4186-d047-e8128b9cbaf8"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Need VERB VB\n",
            "to PART TO\n",
            "finalize VERB VB\n",
            "the DET DT\n",
            "demo NOUN NN\n",
            "corpus NOUN NN\n",
            "which DET WDT\n",
            "will VERB MD\n",
            "be AUX VB\n",
            "used VERB VBN\n",
            "for ADP IN\n",
            "this DET DT\n",
            "notebook NOUN NN\n",
            "and CCONJ CC\n",
            "it PRON PRP\n",
            "should VERB MD\n",
            "be AUX VB\n",
            "done VERB VBN\n",
            "soon ADV RB\n",
            "! PUNCT .\n",
            "! PUNCT .\n",
            ". PUNCT .\n",
            "It PRON PRP\n",
            "should VERB MD\n",
            "be AUX VB\n",
            "done VERB VBN\n",
            "by ADP IN\n",
            "the DET DT\n",
            "ending NOUN NN\n",
            "of ADP IN\n",
            "this DET DT\n",
            "month NOUN NN\n",
            ". PUNCT .\n",
            "But CCONJ CC\n",
            "will VERB MD\n",
            "it PRON PRP\n",
            "? PUNCT .\n",
            "This DET DT\n",
            "notebook NOUN NN\n",
            "has AUX VBZ\n",
            "been AUX VBN\n",
            "run VERB VBN\n",
            "4 NUM CD\n",
            "times NOUN NNS\n",
            "! PUNCT .\n",
            "! PUNCT .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Augmentation"
      ],
      "metadata": {
        "id": "8mJxfE2bA3CP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install nlpaug\n",
        "import nlpaug\n",
        "import nlpaug.augmenter.char as nac\n",
        "import nlpaug.augmenter.word as naw\n",
        "import nlpaug.augmenter.sentence as nas\n",
        "import nlpaug.flow as nafc\n",
        "from nlpaug.util import Action\n",
        "\n",
        "augmented_texts = nac.OcrAug().augment(corpus_original, n=20)"
      ],
      "metadata": {
        "id": "O0p0g8yK8kQQ"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ct4Z-Y27B1bU",
        "outputId": "e0955dfd-f991-4e06-d720-eab64283c8ab"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Need to finalize the demo corpus which will be used f0k this note6o0r and it shoo1d 6e done soon! !. It should be done 6y the ending of this month. But will it? Thi8 notebook has been kon 4 times!!',\n",
              " 'Need to finalize the demo corpus which wi11 6e used for this notebook and it should be done soon! !. It should be done 6y the ending uf this month. Eot will it? This notebook ha8 been run 1 times!!',\n",
              " 'Need to finalize the demu corpus which wi11 be o8ed fuk this notebook and it should be done soon! !. It should be done by the ending of this month. But will it? This n0tebuuk has been run 1 time8!!',\n",
              " 'Need to finalize the demo corpus which wi11 6e used for this n0te6o0k and it should be dune soon! !. It sh0old be done by the endin9 of this month. But wi11 it? This notebook has been run 4 times!!',\n",
              " 'Need t0 finalize the demo corpus which will be used f0k this notebook and it should 6e done soon! !. It should be done by the ending of this month. But will it? Thi8 notebook ha8 been kon 1 times!!',\n",
              " 'Need to finalize the demo c0kpus which will 6e used f0k this notebook and it 8huuld be done 8uon! !. It should be dune by the endin9 of this month. But will it? This notebook has been run 4 time8!!',\n",
              " 'Need t0 finalize the demo corpus which will be used for this n0tebuor and it should 6e done soon! !. It sh0u1d be done 6y the endin9 of this month. Eot will it? Thi8 notebook has 6een run 4 times!!',\n",
              " 'Need to finalize the demo corpus which wi11 be used for this notebook and it should 6e done 80on! !. It should be done by the endin9 of thi8 month. Eot will it? This notebook has been run 4 times!!',\n",
              " 'Need to fina1i2e the demo corpus which wi11 be used for this notebook and it shoo1d be done soon! !. It should be done by the endin9 of this month. But wi11 it? Thi8 notebook has 6een run 1 times!!',\n",
              " 'Need to finalize the dem0 corpus which will be used for this notebook and it should be d0ne soon! !. It should be d0ne by the ending of thi8 month. Eot will it? Thi8 notebu0r has been run 4 times!!',\n",
              " 'Need to finalize the demo corpus which wi11 6e o8ed for thi8 nute6oor and it shoo1d be dune soon! !. It should be done by the endin9 of this month. But will it? This notebook has been run 4 times!!',\n",
              " 'Need to finalize the demo corpo8 which wi11 be used for this n0teb0uk and it should be done soon! !. It should be done by the endin9 of thi8 munth. But will it? This notebook has been run 4 times!!',\n",
              " 'Need to finalize the demo corpus which will be used for this notebook and it 8hou1d be done soon! !. It should 6e done by the ending uf this month. But wi11 it? Thi8 note60or ha8 been kon 4 times!!',\n",
              " 'Need to finalize the demo corpus which will be used for this note6u0k and it should be dune soon! !. It shuold be done by the endin9 of this month. But wi11 it? This notebook has been run 1 times!!',\n",
              " 'Need t0 finalize the demo corpus which will be o8ed for this notebook and it should be done soon! !. 1t should 6e done by the ending uf this munth. But will it? This notebook has 6een run 4 time8!!',\n",
              " 'Need to finalize the demo corpus which wi11 be used for this nute6oor and it should be done soon! !. It 8h0uld be done by the ending of this month. But wi11 it? This nute6oor has 6een run 4 times!!',\n",
              " 'Need to finalize the dem0 corpus which will 6e used for this nutebuuk and it 8hoold be done soon! !. It should be done 6y the endin9 of this month. But will it? This notebook has been kon 4 times!!',\n",
              " 'Need to finalize the demu c0rpos which will be used for this notebook and it should be dune s0un! !. It should be d0ne 6y the ending of this month. But will it? This notebook has been run 1 times!!',\n",
              " 'Need to fina1i2e the demo corpo8 which will be used for this notebook and it should be done 80on! !. It should be done by the ending of thi8 m0nth. But will it? This note6our has been kon 4 times!!',\n",
              " 'Need to finalize the demo corpus which wi11 be used for thi8 notebook and it should be done soon! !. 1t shoo1d 6e d0ne by the ending of this month. But will it? Thi8 notebook has been kon 4 times!!']"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3Bur_r0LC__5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}