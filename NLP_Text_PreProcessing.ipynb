{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-Text-PreProcessing.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Wq31EKDPV0f_",
        "TYPEaAgXV-EN",
        "0mOPQn0DWFdD"
      ],
      "authorship_tag": "ABX9TyPjZY36QtUti55kveWBITKQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/NLP-Text-Processing/blob/main/NLP_Text_PreProcessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GD6K9gKUjIOy"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "import spacy\n",
        "import string\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_original = \"Need to finalize the demo corpus which will be used for this notebook and it should be done soon !!. It should be done by the ending of this month. But will it? This notebook has been run 4 times !!\"\n",
        "corpus = \"Need to finalize the demo corpus which will be used for this notebook & should be done soon !!. It should be done by the ending of this month. But will it? This notebook has been run 4 times !!\""
      ],
      "metadata": {
        "id": "lUrdtzgOoeHL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = re.sub(r'\\d+', '', corpus.lower())"
      ],
      "metadata": {
        "id": "SGHk8_EVogwC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "y4HoUeAZ2Z9S",
        "outputId": "1b130126-8da0-4671-a227-fbbc34f0628d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'need to finalize the demo corpus which will be used for this notebook & should be done soon !!. it should be done by the ending of this month. but will it? this notebook has been run  times !!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = corpus.translate(str.maketrans('', '', string.punctuation))"
      ],
      "metadata": {
        "id": "8UIoZi_H5mJh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(string.punctuation)\n",
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "fXYooP_f53ZM",
        "outputId": "fe702296-8ae9-4066-a5c5-7a7f887ff9ad"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'need to finalize the demo corpus which will be used for this notebook  should be done soon  it should be done by the ending of this month but will it this notebook has been run  times '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = ' '.join([token for token in corpus.split()])"
      ],
      "metadata": {
        "id": "A_FGtycN54l0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "rZdDWisl7RIx",
        "outputId": "ee06fa93-2ad5-49d9-bfa1-efb93dae321a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'need to finalize the demo corpus which will be used for this notebook should be done soon it should be done by the ending of this month but will it this notebook has been run times'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm\n",
        "spacy_model = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJB40W7A7RUl",
        "outputId": "5fdb73c2-a7dc-4a73-968b-9ef2e8988ea5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 939 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.64.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.21.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.9.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tokenize the Text"
      ],
      "metadata": {
        "id": "7Qe5dDXaVTOP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Stop Words"
      ],
      "metadata": {
        "id": "Wq31EKDPV0f_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Stop Words with NLTK"
      ],
      "metadata": {
        "id": "TYPEaAgXV-EN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "GslfQw877VxV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a873f254-7da6-4185-c2c7-321f1791be43"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words_nltk = set(nltk.corpus.stopwords.words('english'))\n",
        "len(stop_words_nltk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tbqzRAmVf1j",
        "outputId": "926c973c-f6cd-4543-d948-4de90a43b43b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_corpus_nltk = nltk.tokenize.word_tokenize(corpus)\n",
        "print(len(tokenized_corpus_nltk))\n",
        "tokenized_corpus_nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IT9D0XmnVoxx",
        "outputId": "6649b261-61a3-4b8f-d53b-cd36ae2d2698"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['need',\n",
              " 'to',\n",
              " 'finalize',\n",
              " 'the',\n",
              " 'demo',\n",
              " 'corpus',\n",
              " 'which',\n",
              " 'will',\n",
              " 'be',\n",
              " 'used',\n",
              " 'for',\n",
              " 'this',\n",
              " 'notebook',\n",
              " 'should',\n",
              " 'be',\n",
              " 'done',\n",
              " 'soon',\n",
              " 'it',\n",
              " 'should',\n",
              " 'be',\n",
              " 'done',\n",
              " 'by',\n",
              " 'the',\n",
              " 'ending',\n",
              " 'of',\n",
              " 'this',\n",
              " 'month',\n",
              " 'but',\n",
              " 'will',\n",
              " 'it',\n",
              " 'this',\n",
              " 'notebook',\n",
              " 'has',\n",
              " 'been',\n",
              " 'run',\n",
              " 'times']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_words_without_stopwords_nltk = [i for i in tokenized_corpus_nltk if i not in stop_words_nltk] \n",
        "print(len(tokenized_words_without_stopwords_nltk))\n",
        "tokenized_words_without_stopwords_nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySc_d36KWchx",
        "outputId": "a57d43ef-fdd5-4589-d14e-63bf83659d20"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['need',\n",
              " 'finalize',\n",
              " 'demo',\n",
              " 'corpus',\n",
              " 'used',\n",
              " 'notebook',\n",
              " 'done',\n",
              " 'soon',\n",
              " 'done',\n",
              " 'ending',\n",
              " 'month',\n",
              " 'notebook',\n",
              " 'run',\n",
              " 'times']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Stop Words with Spacy"
      ],
      "metadata": {
        "id": "0mOPQn0DWFdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "spacy_model = spacy.load('en_core_web_sm')\n",
        "\n",
        "stop_words_sparcy = spacy_model.Defaults.stop_words\n",
        "len(stop_words_sparcy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0v-e12CVpwt",
        "outputId": "a245564e-eef0-4331-922f-ae2d88d3f0b5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "326"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_corpus_sparcy = nltk.tokenize.word_tokenize(corpus)\n",
        "print(len(tokenized_corpus_sparcy))\n",
        "tokenized_corpus_sparcy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78E4HiAyXqK7",
        "outputId": "8f4223d1-c1bd-45de-992d-182f41c09a2b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['need',\n",
              " 'to',\n",
              " 'finalize',\n",
              " 'the',\n",
              " 'demo',\n",
              " 'corpus',\n",
              " 'which',\n",
              " 'will',\n",
              " 'be',\n",
              " 'used',\n",
              " 'for',\n",
              " 'this',\n",
              " 'notebook',\n",
              " 'should',\n",
              " 'be',\n",
              " 'done',\n",
              " 'soon',\n",
              " 'it',\n",
              " 'should',\n",
              " 'be',\n",
              " 'done',\n",
              " 'by',\n",
              " 'the',\n",
              " 'ending',\n",
              " 'of',\n",
              " 'this',\n",
              " 'month',\n",
              " 'but',\n",
              " 'will',\n",
              " 'it',\n",
              " 'this',\n",
              " 'notebook',\n",
              " 'has',\n",
              " 'been',\n",
              " 'run',\n",
              " 'times']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_words_without_stopwords_sparcy = [i for i in tokenized_corpus_sparcy if i not in stop_words_sparcy] \n",
        "print(len(tokenized_words_without_stopwords_sparcy))\n",
        "tokenized_words_without_stopwords_sparcy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yg9MuBakXhgf",
        "outputId": "8fdd9708-8564-4d68-9feb-6a7dd2d319e0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['need',\n",
              " 'finalize',\n",
              " 'demo',\n",
              " 'corpus',\n",
              " 'notebook',\n",
              " 'soon',\n",
              " 'ending',\n",
              " 'month',\n",
              " 'notebook',\n",
              " 'run',\n",
              " 'times']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('The Difference between nltk and sparcy in stop words:\\n')\n",
        "set(tokenized_words_without_stopwords_nltk) - set(tokenized_words_without_stopwords_sparcy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBKvuJ6BXjGS",
        "outputId": "5fea088c-9dc3-415b-c507-aa756b8a880a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Difference between nltk and sparcy in stop words:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'done', 'used'}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pyenchant\n",
        "# import enchant\n",
        "# from enchant import DictWithPWL\n",
        "# from enchant.checker import SpellChecker\n",
        "\n",
        "# my_dict = DictWithPWL(\"en_US\", \"mywords.txt\")\n",
        "# my_checker = SpellChecker(my_dict)\n",
        "\n",
        "# my_checker.set_text(\"This is sme sample txt with erors.\")\n",
        "# for error in my_checker:\n",
        "#     print (\"ERROR:\", error.word)"
      ],
      "metadata": {
        "id": "s663r3tuYbdz"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Lemmatization"
      ],
      "metadata": {
        "id": "4n3WpiEo55c6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "o0uYIS7D2ZFC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a221b9c7-688d-43de-8cee-2233dd14477c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in tokenized_words_without_stopwords_nltk:\n",
        "  print(lemmatizer.lemmatize(word), end=' ')"
      ],
      "metadata": {
        "id": "wSrNiBXU6eFC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7be3a32-f588-459e-b6e3-6d10d65e7111"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "need finalize demo corpus used notebook done soon done ending month notebook run time "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in tokenized_corpus_nltk:\n",
        "  print(lemmatizer.lemmatize(word), end=' ')"
      ],
      "metadata": {
        "id": "k0PWLK-564M-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "878a0bf1-6783-49a4-8e03-8ddbc1714793"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "need to finalize the demo corpus which will be used for this notebook should be done soon it should be done by the ending of this month but will it this notebook ha been run time "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###POS Tagging"
      ],
      "metadata": {
        "id": "YPFHo1nE7y1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = spacy_model(corpus_original)"
      ],
      "metadata": {
        "id": "xsEjw8BO7mJ7"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  print(token, token.pos_, token.tag_)"
      ],
      "metadata": {
        "id": "TzwS1PGs8W_4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e43ec382-183f-4177-e710-dc709c1236ca"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Need VERB VB\n",
            "to PART TO\n",
            "finalize VERB VB\n",
            "the DET DT\n",
            "demo NOUN NN\n",
            "corpus NOUN NN\n",
            "which DET WDT\n",
            "will VERB MD\n",
            "be AUX VB\n",
            "used VERB VBN\n",
            "for ADP IN\n",
            "this DET DT\n",
            "notebook NOUN NN\n",
            "and CCONJ CC\n",
            "it PRON PRP\n",
            "should VERB MD\n",
            "be AUX VB\n",
            "done VERB VBN\n",
            "soon ADV RB\n",
            "! PUNCT .\n",
            "! PUNCT .\n",
            ". PUNCT .\n",
            "It PRON PRP\n",
            "should VERB MD\n",
            "be AUX VB\n",
            "done VERB VBN\n",
            "by ADP IN\n",
            "the DET DT\n",
            "ending NOUN NN\n",
            "of ADP IN\n",
            "this DET DT\n",
            "month NOUN NN\n",
            ". PUNCT .\n",
            "But CCONJ CC\n",
            "will VERB MD\n",
            "it PRON PRP\n",
            "? PUNCT .\n",
            "This DET DT\n",
            "notebook NOUN NN\n",
            "has AUX VBZ\n",
            "been AUX VBN\n",
            "run VERB VBN\n",
            "4 NUM CD\n",
            "times NOUN NNS\n",
            "! PUNCT .\n",
            "! PUNCT .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Augmentation"
      ],
      "metadata": {
        "id": "8mJxfE2bA3CP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nlpaug\n",
        "import nlpaug\n",
        "import nlpaug.augmenter.char as nac\n",
        "import nlpaug.augmenter.word as naw\n",
        "import nlpaug.augmenter.sentence as nas\n",
        "import nlpaug.flow as nafc\n",
        "from nlpaug.util import Action\n"
      ],
      "metadata": {
        "id": "O0p0g8yK8kQQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be0debbe-87df-40df-d9ed-ca6e7aa15cb8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nlpaug\n",
            "  Downloading nlpaug-1.1.10-py3-none-any.whl (410 kB)\n",
            "\u001b[K     |████████████████████████████████| 410 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from nlpaug) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.7/dist-packages (from nlpaug) (1.21.6)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from nlpaug) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->nlpaug) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->nlpaug) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->nlpaug) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->nlpaug) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->nlpaug) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->nlpaug) (2.10)\n",
            "Installing collected packages: nlpaug\n",
            "Successfully installed nlpaug-1.1.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_texts = nac.OcrAug().augment(corpus_original, n=20)\n",
        "augmented_texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ct4Z-Y27B1bU",
        "outputId": "b5f02353-1863-42b6-c9ea-f3835030a511"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Need to finalize the demo corpus which will be used for this notebook and it sh0u1d be d0ne soon! !. It should be done by the endin9 of thi8 month. But will it? This notebook has been run 4 time8!!',\n",
              " 'Need to finalize the demu corpus which will be used for thi8 notebook and it should be done soon! !. It should be d0ne 6y the ending 0f this month. But will it? This n0teb0or has been run 1 times!!',\n",
              " 'Need to fina1i2e the demo corpus which will be used for this notebook and it should be done soon! !. It should be done by the ending of this month. But will it? Thi8 notebuur has been kon 4 times!!',\n",
              " 'Need to fina1i2e the demu corpus which wi11 be used for this notebook and it should be done s0un! !. It should be d0ne by the ending of this month. Eot will it? This notebook has been run 4 time8!!',\n",
              " 'Need t0 finalize the demo corpus which will be o8ed for this n0teb0or and it should be dune soon! !. 1t should 6e done by the ending of this month. But will it? This n0teb0uk has been run 4 times!!',\n",
              " 'Need to fina1i2e the demo corpus which will be used for this notebook and it 8hou1d 6e done soon! !. It shoo1d be done 6y the endin9 of this month. But will it? Thi8 notebook has been run 1 times!!',\n",
              " 'Need t0 fina1i2e the demo corpus which will be used for thi8 notebook and it should be done 8oun! !. It should be done by the endin9 of this m0nth. But wi11 it? This notebook has been run 4 time8!!',\n",
              " 'Need t0 fina1i2e the demo corpus which will be used for this nute6ouk and it should be done soon! !. It 8huuld be done by the endin9 of this munth. But will it? This notebook has been run 1 times!!',\n",
              " 'Need to finalize the demo corpus which will be used for this notebook and it sh0u1d be done soon! !. 1t should 6e done 6y the ending of thi8 m0nth. But will it? This notebook ha8 been kon 4 times!!',\n",
              " 'Need to finalize the demo corpus which will be o8ed for thi8 notebook and it should be done soon! !. It should be d0ne 6y the ending of this month. But wi11 it? This notebook has been run 1 time8!!',\n",
              " 'Need to finalize the demo corpus which will be used for this notebook and it should be dune 8uon! !. It should 6e done 6y the ending uf thi8 month. But will it? This notebook has been kon 1 times!!',\n",
              " 'Need to fina1i2e the dem0 corpus which wi11 be used for this notebook and it should be done soon! !. It should be done 6y the ending of this month. But will it? Thi8 note6uuk has been run 4 time8!!',\n",
              " 'Need to finalize the demo corpus which wi11 be used for thi8 note6uor and it should 6e done soon! !. It should be done by the ending of this month. But will it? This notebuur has been run 1 times!!',\n",
              " 'Need tu finalize the demo cukpus which will be used for this n0tebu0k and it should be done 8uon! !. It should 6e done by the ending of this month. But will it? This notebook has been run 4 times!!',\n",
              " 'Need to finalize the demo corpus which will be used f0k this notebook and it should 6e done soon! !. It 8huuld 6e dune by the endin9 of this month. Eot will it? This notebook has been kon 4 times!!',\n",
              " 'Need to fina1i2e the demu corpus which will be o8ed for thi8 notebook and it should be done soon! !. It should be done by the ending of this month. Eot will it? This notebook has 6een run 4 time8!!',\n",
              " 'Need to finalize the demo corpus which will be used for this n0tebu0k and it 8h0uld 6e done soon! !. 1t should be done by the ending of thi8 month. But will it? This note6uor ha8 been kon 4 times!!',\n",
              " 'Need to fina1i2e the demo corpus which will be used for this notebook and it should be done 8uon! !. 1t should be done by the ending of this munth. But will it? This notebook ha8 6een run 4 time8!!',\n",
              " 'Need to finalize the demo corpus which will be used fuk this notebook and it should be dune soon! !. It should be done by the endin9 of thi8 munth. Eot will it? This notebook has been run 4 times!!',\n",
              " 'Need to finalize the demo corpus which will be used for thi8 notebook and it should be done 8uon! !. It sh0u1d be d0ne 6y the endin9 0f this month. But will it? This notebook has been kon 4 times!!']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_texts = nac.KeyboardAug().augment(corpus_original, n=20)\n",
        "augmented_texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Bur_r0LC__5",
        "outputId": "c1f5d92e-22e3-47e3-f722-340755db4738"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Need to finalize the EDmo coDp^s wUicM #iOl be used for this nkgebooI and it sYoukd be done soon! !. It wh*uld be done by the ending of this month. But #i?l it? ^hUs notebook has been run 4 gihes!!',\n",
              " 'Nrec to finalize the VeKo corpus which will be used for tnix nohSbopk and it Dho7ld be done soon! !. It should be SoGe by the endOnF of this month. But will it? This not4b80k has be#j run 4 $i<es!!',\n",
              " 'Need to finalize the demo corpus wh8vh will be used for 5Uis jotFbooj and it QhouKd be d(he soon! !. It Cmould be done by the ending of this month. But Skll it? Th7d n9trbolk has bSRn run 4 times!!',\n",
              " 'Need to fins.izw the demo ci5pus which will be iseC for this noH@blok and it should be d0he sIoj! !. It snoKld be done by the eMdiGg of this month. But will it? This gpteNook has HeeG run 4 times!!',\n",
              " 'herd to finalize the demo co5)us which Ai<l be 8ssd for tM9s notebook and it should be done soon! !. It should be done by the ending of this <omth. But EiPl it? RhJs n0tfbPok has bWeJ run 4 times!!',\n",
              " 'Need to finalize the sdmo c9rpuC wh8dh w*Kl be used for this notebook and it sgoild be RKne soon! !. It should be dogR by the ending of this month. But will it? This n8$eboom has f4en run 4 t7Nes!!',\n",
              " 'Need to fiBa:iz@ the demo co$p Ts !h(ch will be used for this notebook and it should be von3 soon! !. It should be domr by the ending of hyis mob$h. But wkl< it? Fh7s notebook has bdeb run 4 times!!',\n",
              " 'N#eW to finalize the demo corpus which 3iPl be &Aed for this notebook and it cTould be done soon! !. It should be d8Me by the Dndimg of $mis month. But will it? 4hJs moteV8ok has be@M run 4 times!!',\n",
              " 'Need to finWouze the demo corpus which will be used for thoQ notebook and it sg8uld be xine soon! !. It should be dogd by the eGdiGg of this mInGh. But will it? TUks n)teNiok has bFeG run 4 times!!',\n",
              " 'Need to finalize the Eeho corpus which @oll be used for thKD notebook and it sh(ule be done sIoB! !. It sUohld be Xlne by the ending of %h(s month. But Eil< it? This notebook has bfDn run 4 times!!',\n",
              " 'Need to finaPix# the demo corpus which w9;l be used for 5hic notebook and it shoklC be SIne soon! !. It sho*lf be r)ne by the enEinr of thlq month. But qilo it? This notebook has been run 4 times!!',\n",
              " 'hFed to ViGaliae the demo corpus which wJ?l be used for this BLtdbook and it shou?S be done soon! !. It should be done by the endiHN of tjJs m8ntB. But will it? This not4b(oJ has heeH run 4 times!!',\n",
              " 'Need to finalize the X2mo corpus !hicG will be usss for this n9yehook and it sGo8ld be done soon! !. It sho8lr be done by the endUnB of hhks monHN. But will it? This notebook has been run 4 tijec!!',\n",
              " 'Need to Ginwl8ze the demo corpus which will be used for tYiC notebook and it should be fkne Wo9n! !. It QhoJld be XoJe by the ending of Rhia mintG. But will it? TJUs b85ebook has been run 4 times!!',\n",
              " 'Need to VinaliX# the d2No corpus which dil, be used for this m*teb*ok and it shIJld be rPne soon! !. It sNoKld be done by the ending of this mobRh. But will it? This notebook has hern run 4 ti<eZ!!',\n",
              " 'Need to fOnalOzr the demo c0tpus wB(ch will be used for this notrb)oi and it should be done zo0n! !. It should be done by the endibF of RhiZ moB5h. But will it? This notebook has bsRn run 4 tUmeA!!',\n",
              " 'bSed to finZlUae the cem( corpus wTlch wjlK be used for this notebook and it sh9ild be done zoom! !. It should be done by the ending of this month. But AJll it? 6hie GofebooJ has been run 4 times!!',\n",
              " 'Need to BiMaliAe the x4mo corpus wJkch will be uXRd for this moY2book and it ehoKld be done soon! !. It should be done by the endKbg of Fh(s NonFh. But will it? This notebook has been run 4 t&m#s!!',\n",
              " 'beRd to finalize the xejo corpus which will be 6seF for this notRblPk and it zhluld be done so0M! !. It should be F0ne by the emdibg of this month. But will it? yTis notebook has been run 4 4imSs!!',\n",
              " 'Meer to fiHaijze the demo corpus which !il; be used for fhiq noFeboij and it should be d0Ge soon! !. It xhoulv be Voge by the ending of tBLs J9nth. But will it? This notebook has been run 4 times!!']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_texts = naw.SpellingAug().augment(corpus_original, n=20)\n",
        "augmented_texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWp9OxOHDm2_",
        "outputId": "bb44cef1-5624-4949-a131-dd32c00cf09e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Need to finalize tthe demo corpus which will be used for this notebook and it shloud be down soon! !. It should br done by the ending 0f this morth. Bur wiIl it? This notebook has beeb runin 4 times!!',\n",
              " \"Need to finalize the demo corpus hich will be usee for this notebook and it should be done seen! !. It should be done yb thre ending of this month. But we'll it? This notebook have been runs 5 timens!!\",\n",
              " \"Need top finalize the demo corpus which we'l be used aslo this notebook and it should be done see! !. lt should be down by the ending ok this month. But will ii? This notebook has been rum 4 timens!!\",\n",
              " \"Need to finalize athe demo corpus which will bee used for this notebook ou ii should be done soon! !. Ir should be dane Buy there ending aof this month. But will it's.? This notebook has been run 4 times!!\",\n",
              " 'Need o finalize tha demo corpus which will be used for thhis notebook abd it should be done oon! !. It shoold be done by the endding of this month. But will it? This notbook has been runin 4 timeas!!',\n",
              " 'Need toa finalize th? demo corpus which will be used for ther netbook and it should ne done sun! !. It should be done by the ending of thois month. ?ut will it? Thise notebook was been run 4 times!!',\n",
              " \"Need to finalize thwe demo corpus [[wich will be used fr htis nootebook and it's. should se done soo! !. Tt should be done by the ending of this month. But will it? This notebook has seen run 4 times!!\",\n",
              " \"Need to finalize the demo corpus which will be used for theis notebook and it's should be done noon! !. It shoulds be done by tie ending of this muth. But will it? Thi's notebook hac beeb run 4 timeas!!\",\n",
              " 'Need to finalize the demo corpus which will se uses for this notebook nand it should be done soon! !. It should we done by tu end of these mount. But will il? This notebook have been run 4 times!!',\n",
              " 'Need you. finalize the demo corpus which whi be usd for this nootebook and it shoulg bè dane soon! !. It should he done by the ending of this month. But waill it? Thie notebook has been run 4 times!!',\n",
              " 'Need to finalize tne demo corpus which will br used for this notebook and it shoold be done soon! !. It should bee done by the ending f this month. Bat will it? This netbook has been rung 4th tames!!',\n",
              " 'Need to finalize the demo corpus which will [[bi used por ths notebook and t should be done soos! !. It should be doen by the ending oof this month. But will it? This netbook was seen run 4 times!!',\n",
              " 'Need to finalize thi demo corpus witch will [[bi used for thi notebook and it should be done soon! !. It should be done by the ending of htis month. But will it? Thies notebook was benn rung 4th times!!',\n",
              " 'Need to finalize the demo corpus which will be uesd for this notebook e it should bem down soon! !. IT shoul be dane by the end of ti month. But will it? This notebook has been run 5 times!!',\n",
              " \"Need to finalize the demo corpus which wall be used for this notebook ah It's should be done soon! !. It shoule br done by the ending of this mounth.. But w'll it? This notebook haves been run 4th time!!\",\n",
              " \"Need to finalize the demo corpus which will be used for this netbook and ti should be done soo! !. It should ne done bye! the ending lf this mont. But will I'ts? This netbook has seen run 4 times!!\",\n",
              " 'Need to finalize the demo corpus whuch wii be used for this notebook and it should be down see! !. It should be doen by the ending of thease month. But well it? This netbook has being run 5 times!!',\n",
              " 'Need yo finalize the demo corpus which wlii be usee for this notebook and it shuld be doen soon! !. It shloud be down by the ending of this moth. But will it? This notebook hat been rum 4 times!!',\n",
              " \"Need take finalize tte demo corpus which will by used for this's notebook and it should be done soon! !. It shoul we done Bye the ending of this month. But will it? This notebook hac beans ran 4 times!!\",\n",
              " \"Need to finalize the demo corpus which will be used forth this notebook in it woud be done soon! !. It's should he done by thd ending aof this month. But will it? Thise notebook had been rune 4 times!!\"]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Example 1"
      ],
      "metadata": {
        "id": "ezjxjJ4juRXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = '''\n",
        "man bite dog\n",
        "dog bite man\n",
        "man eat meat\n",
        "dog eat meat\n",
        "man like ball\n",
        "man like dog\n",
        "'''"
      ],
      "metadata": {
        "id": "4YjhFUFjEZWC"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = set(sample_text.split())"
      ],
      "metadata": {
        "id": "Du6h6gHUvCWH"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RggdJQ7pEJP0",
        "outputId": "19d4c224-0a92-48d1-bc0d-c849880a7d1f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ball', 'bite', 'dog', 'eat', 'like', 'man', 'meat'}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FJ5w5urpELYp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}