{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-Text-PreProcessing.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Wq31EKDPV0f_",
        "TYPEaAgXV-EN",
        "0mOPQn0DWFdD"
      ],
      "authorship_tag": "ABX9TyMcMolvy4aWOirQVVeQguQX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/NLP-Text-Processing/blob/main/NLP_Text_PreProcessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GD6K9gKUjIOy"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "import spacy\n",
        "import string\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_original = \"Need to finalize the demo corpus which will be used for this notebook and it should be done soon !!. It should be done by the ending of this month. But will it? This notebook has been run 4 times !!\"\n",
        "corpus = \"Need to finalize the demo corpus which will be used for this notebook & should be done soon !!. It should be done by the ending of this month. But will it? This notebook has been run 4 times !!\""
      ],
      "metadata": {
        "id": "lUrdtzgOoeHL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = re.sub(r'\\d+', '', corpus.lower())"
      ],
      "metadata": {
        "id": "SGHk8_EVogwC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "y4HoUeAZ2Z9S",
        "outputId": "cd696740-3226-4c90-844f-208bcf3ebb51"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'need to finalize the demo corpus which will be used for this notebook & should be done soon !!. it should be done by the ending of this month. but will it? this notebook has been run  times !!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = corpus.translate(str.maketrans('', '', string.punctuation))"
      ],
      "metadata": {
        "id": "8UIoZi_H5mJh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(string.punctuation)\n",
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "fXYooP_f53ZM",
        "outputId": "3d14ce5f-cbb5-4e60-b10e-c3730126223d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'need to finalize the demo corpus which will be used for this notebook should be done soon it should be done by the ending of this month but will it this notebook has been run times'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = ' '.join([token for token in corpus.split()])"
      ],
      "metadata": {
        "id": "A_FGtycN54l0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "rZdDWisl7RIx",
        "outputId": "4a0570c0-0955-43a8-e355-80f4b48cf04c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'need to finalize the demo corpus which will be used for this notebook should be done soon it should be done by the ending of this month but will it this notebook has been run times'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm\n",
        "spacy_model = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJB40W7A7RUl",
        "outputId": "80015429-9c89-4d06-ea47-f064f36be39d"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.7)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.9.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.64.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.10.8)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tokenize the Text"
      ],
      "metadata": {
        "id": "7Qe5dDXaVTOP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Stop Words"
      ],
      "metadata": {
        "id": "Wq31EKDPV0f_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Stop Words with NLTK"
      ],
      "metadata": {
        "id": "TYPEaAgXV-EN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "GslfQw877VxV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba13437a-ab38-49e6-ce91-d8cb2db5a999"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words_nltk = set(nltk.corpus.stopwords.words('english'))\n",
        "len(stop_words_nltk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tbqzRAmVf1j",
        "outputId": "fad0e245-85cf-4bbd-e013-95c18dd28e56"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_corpus_nltk = nltk.tokenize.word_tokenize(corpus)\n",
        "print(len(tokenized_corpus_nltk))\n",
        "tokenized_corpus_nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IT9D0XmnVoxx",
        "outputId": "c0fe94ae-1fac-4c9b-a046-4f1747861828"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['need',\n",
              " 'to',\n",
              " 'finalize',\n",
              " 'the',\n",
              " 'demo',\n",
              " 'corpus',\n",
              " 'which',\n",
              " 'will',\n",
              " 'be',\n",
              " 'used',\n",
              " 'for',\n",
              " 'this',\n",
              " 'notebook',\n",
              " 'should',\n",
              " 'be',\n",
              " 'done',\n",
              " 'soon',\n",
              " 'it',\n",
              " 'should',\n",
              " 'be',\n",
              " 'done',\n",
              " 'by',\n",
              " 'the',\n",
              " 'ending',\n",
              " 'of',\n",
              " 'this',\n",
              " 'month',\n",
              " 'but',\n",
              " 'will',\n",
              " 'it',\n",
              " 'this',\n",
              " 'notebook',\n",
              " 'has',\n",
              " 'been',\n",
              " 'run',\n",
              " 'times']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_words_without_stopwords_nltk = [i for i in tokenized_corpus_nltk if i not in stop_words_nltk] \n",
        "print(len(tokenized_words_without_stopwords_nltk))\n",
        "tokenized_words_without_stopwords_nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySc_d36KWchx",
        "outputId": "eb4d5cfc-bed5-4468-c54a-2f6e1a466780"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['need',\n",
              " 'finalize',\n",
              " 'demo',\n",
              " 'corpus',\n",
              " 'used',\n",
              " 'notebook',\n",
              " 'done',\n",
              " 'soon',\n",
              " 'done',\n",
              " 'ending',\n",
              " 'month',\n",
              " 'notebook',\n",
              " 'run',\n",
              " 'times']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Stop Words with Spacy"
      ],
      "metadata": {
        "id": "0mOPQn0DWFdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "spacy_model = spacy.load('en_core_web_sm')\n",
        "\n",
        "stop_words_sparcy = spacy_model.Defaults.stop_words\n",
        "len(stop_words_sparcy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0v-e12CVpwt",
        "outputId": "4d35f323-abb6-466a-f21b-652dbc888aa8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "326"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_corpus_sparcy = nltk.tokenize.word_tokenize(corpus)\n",
        "print(len(tokenized_corpus_sparcy))\n",
        "tokenized_corpus_sparcy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78E4HiAyXqK7",
        "outputId": "c522e388-7caf-4294-b640-819f3958a684"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['need',\n",
              " 'to',\n",
              " 'finalize',\n",
              " 'the',\n",
              " 'demo',\n",
              " 'corpus',\n",
              " 'which',\n",
              " 'will',\n",
              " 'be',\n",
              " 'used',\n",
              " 'for',\n",
              " 'this',\n",
              " 'notebook',\n",
              " 'should',\n",
              " 'be',\n",
              " 'done',\n",
              " 'soon',\n",
              " 'it',\n",
              " 'should',\n",
              " 'be',\n",
              " 'done',\n",
              " 'by',\n",
              " 'the',\n",
              " 'ending',\n",
              " 'of',\n",
              " 'this',\n",
              " 'month',\n",
              " 'but',\n",
              " 'will',\n",
              " 'it',\n",
              " 'this',\n",
              " 'notebook',\n",
              " 'has',\n",
              " 'been',\n",
              " 'run',\n",
              " 'times']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_words_without_stopwords_sparcy = [i for i in tokenized_corpus_sparcy if i not in stop_words_sparcy] \n",
        "print(len(tokenized_words_without_stopwords_sparcy))\n",
        "tokenized_words_without_stopwords_sparcy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yg9MuBakXhgf",
        "outputId": "889a72c9-d4d2-4d39-8512-472b1184a980"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['need',\n",
              " 'finalize',\n",
              " 'demo',\n",
              " 'corpus',\n",
              " 'notebook',\n",
              " 'soon',\n",
              " 'ending',\n",
              " 'month',\n",
              " 'notebook',\n",
              " 'run',\n",
              " 'times']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('The Difference between nltk and sparcy in stop words:\\n')\n",
        "set(tokenized_words_without_stopwords_nltk) - set(tokenized_words_without_stopwords_sparcy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBKvuJ6BXjGS",
        "outputId": "051e6ae6-a694-4e3b-b4d4-5798728a100e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Difference between nltk and sparcy in stop words:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'done', 'used'}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pyenchant\n",
        "import enchant\n",
        "from enchant import DictWithPWL\n",
        "from enchant.checker import SpellChecker\n",
        "\n",
        "my_dict = DictWithPWL(\"en_US\", \"mywords.txt\")\n",
        "my_checker = SpellChecker(my_dict)\n",
        "\n",
        "my_checker.set_text(\"This is sme sample txt with erors.\")\n",
        "for error in my_checker:\n",
        "    print (\"ERROR:\", error.word)"
      ],
      "metadata": {
        "id": "s663r3tuYbdz"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Lemmatization"
      ],
      "metadata": {
        "id": "4n3WpiEo55c6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0uYIS7D2ZFC",
        "outputId": "223ed053-dec2-48dd-9db7-86f0534b1d9d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in tokenized_words_without_stopwords_nltk:\n",
        "  print(lemmatizer.lemmatize(word), end=' ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSrNiBXU6eFC",
        "outputId": "aac3e544-3ef9-46bd-9c31-5c97f163c70c"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "need finalize demo corpus used notebook done soon done ending month notebook run time "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in tokenized_corpus_nltk:\n",
        "  print(lemmatizer.lemmatize(word), end=' ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0PWLK-564M-",
        "outputId": "84da2bb5-4b9e-4b1f-cac6-682ba530d33a"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "need to finalize the demo corpus which will be used for this notebook should be done soon it should be done by the ending of this month but will it this notebook ha been run time "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###POS Tagging"
      ],
      "metadata": {
        "id": "YPFHo1nE7y1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = spacy_model(corpus_original)"
      ],
      "metadata": {
        "id": "xsEjw8BO7mJ7"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  print(token, token.pos_, token.tag_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzwS1PGs8W_4",
        "outputId": "4108e2de-da41-4186-d047-e8128b9cbaf8"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Need VERB VB\n",
            "to PART TO\n",
            "finalize VERB VB\n",
            "the DET DT\n",
            "demo NOUN NN\n",
            "corpus NOUN NN\n",
            "which DET WDT\n",
            "will VERB MD\n",
            "be AUX VB\n",
            "used VERB VBN\n",
            "for ADP IN\n",
            "this DET DT\n",
            "notebook NOUN NN\n",
            "and CCONJ CC\n",
            "it PRON PRP\n",
            "should VERB MD\n",
            "be AUX VB\n",
            "done VERB VBN\n",
            "soon ADV RB\n",
            "! PUNCT .\n",
            "! PUNCT .\n",
            ". PUNCT .\n",
            "It PRON PRP\n",
            "should VERB MD\n",
            "be AUX VB\n",
            "done VERB VBN\n",
            "by ADP IN\n",
            "the DET DT\n",
            "ending NOUN NN\n",
            "of ADP IN\n",
            "this DET DT\n",
            "month NOUN NN\n",
            ". PUNCT .\n",
            "But CCONJ CC\n",
            "will VERB MD\n",
            "it PRON PRP\n",
            "? PUNCT .\n",
            "This DET DT\n",
            "notebook NOUN NN\n",
            "has AUX VBZ\n",
            "been AUX VBN\n",
            "run VERB VBN\n",
            "4 NUM CD\n",
            "times NOUN NNS\n",
            "! PUNCT .\n",
            "! PUNCT .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Augmentation"
      ],
      "metadata": {
        "id": "8mJxfE2bA3CP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install nlpaug\n",
        "import nlpaug\n",
        "import nlpaug.augmenter.char as nac\n",
        "import nlpaug.augmenter.word as naw\n",
        "import nlpaug.augmenter.sentence as nas\n",
        "import nlpaug.flow as nafc\n",
        "from nlpaug.util import Action\n"
      ],
      "metadata": {
        "id": "O0p0g8yK8kQQ"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_texts = nac.OcrAug().augment(corpus_original, n=20)\n",
        "augmented_texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ct4Z-Y27B1bU",
        "outputId": "f58d0819-0d96-4954-f48b-f6875f03ccc7"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Need to finalize the demo corpus which will 6e used for this notebook and it 8hoold be done soon! !. It should be done by the ending of this month. But wi11 it? Thi8 notebook has been run 1 time8!!',\n",
              " 'Need to finalize the dem0 c0rpos which will be used for this notebook and it should 6e dune 8uon! !. It shuold be done by the endin9 of this month. But will it? This notebook has been run 1 time8!!',\n",
              " 'Need to finalize the dem0 corpo8 which will be used for this note600k and it should be done soon! !. It should 6e done by the ending of thi8 month. But will it? This notebook ha8 6een run 4 times!!',\n",
              " 'Need to finalize the demo corpus which wi11 be used f0k this note6uuk and it should 6e done 8o0n! !. It should be done by the endin9 of this month. Eot will it? This notebook has been run 4 times!!',\n",
              " 'Need to finalize the demo cokpos which will 6e o8ed f0k this notebook and it should be done soon! !. It should be done by the ending uf this month. But will it? Thi8 notebook has 6een run 4 times!!',\n",
              " 'Need to fina1i2e the demu corpus which will be o8ed for this noteb0ur and it shuold be d0ne soon! !. It 8hou1d be done by the ending uf this month. But will it? This notebook ha8 been run 4 times!!',\n",
              " 'Need t0 finalize the demo corpus which will be used f0k this notebook and it should be done soon! !. It should be done by the ending uf thi8 munth. Eot will it? This n0te6o0k has been run 4 times!!',\n",
              " 'Need tu finalize the demo corpus which will be used for thi8 notebook and it should be done soon! !. It should be done by the endin9 uf this munth. But will it? This notebook has been kon 4 times!!',\n",
              " 'Need t0 finalize the demo corpus which will be o8ed for thi8 notebook and it 8hou1d be done soon! !. It should be dune by the ending of this month. But wi11 it? This notebook has 6een run 1 times!!',\n",
              " 'Need to finalize the dem0 curpu8 which will be used for this n0tebuor and it should 6e done soon! !. It should 6e done 6y the ending of this m0nth. Eot will it? This notebook has been run 1 times!!',\n",
              " 'Need t0 finalize the demo corpo8 which wi11 be used for this notebook and it should be d0ne soon! !. It 8huuld be done by the ending uf this month. But wi11 it? This notebook has been run 4 time8!!',\n",
              " 'Need to finalize the demo c0rpos which will be used for this notebook and it should be done soon! !. It should be d0ne 6y the endin9 of this munth. But will it? This notebook has been kon 4 times!!',\n",
              " 'Need to finalize the demo corpus which will 6e used for this notebook and it shuu1d 6e done soon! !. 1t should be done by the endin9 0f this month. But wi11 it? Thi8 notebook ha8 6een run 4 times!!',\n",
              " 'Need to finalize the demu corpus which wi11 be used for this notebook and it should be done soon! !. It shoo1d be done by the ending of this month. But will it? This notebook has 6een run 1 time8!!',\n",
              " 'Need to finalize the demo corpus which will 6e used fuk this notebook and it should be dune soon! !. It should 6e done by the ending of this month. But will it? This notebook has been kon 1 times!!',\n",
              " 'Need to finalize the demo corpus which wi11 be used for this notebook and it should 6e done soon! !. It should be dune by the endin9 0f this month. But will it? This notebook has been run 4 time8!!',\n",
              " 'Need to finalize the demo corpus which will 6e used fuk thi8 notebook and it should be done soon! !. It should be done 6y the ending uf this m0nth. But will it? Thi8 n0te6oor has been run 4 time8!!',\n",
              " 'Need to finalize the demo corpus which will be used for this n0tebuuk and it should be done soon! !. 1t shuu1d 6e done by the endin9 of this month. But will it? This notebook has been run 4 times!!',\n",
              " 'Need to finalize the demu corpus which wi11 be used for this n0te60ok and it 8hou1d be done soon! !. It should be done 6y the ending uf this month. Eot will it? This nutebuor has been run 1 times!!',\n",
              " 'Need to finalize the demo corpus which will be used for this notebook and it should be done soon! !. 1t should be dune by the ending uf this month. Eot wi11 it? Thi8 notebook ha8 been run 4 time8!!']"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_texts = nac.KeyboardAug().augment(corpus_original, n=20)\n",
        "augmented_texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Bur_r0LC__5",
        "outputId": "e20afc79-02fe-4fdb-8448-a8c4e1ec65b2"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Need to finalize the demo cIrLus 3h9ch wo?l be used for tMiC notebook and it sh)u/d be done soon! !. It qhouId be done by the ending of this m8ntn. But will it? Tgix noGRboo< has GFen run 4 times!!',\n",
              " 'Need to finalize the d2mI coGpuC which wLlK be hsfd for gh8s notebook and it should be done s)oH! !. It should be done by the emxing of %bis kKnth. But will it? This notebook has F$en run 4 times!!',\n",
              " 'meSd to fina,kAe the demo corpus wjJch will be uW4d for this Hitebokk and it ehouId be foje soon! !. It should be done by the ending of this month. But 2iil it? TtiQ not#Go)k has been run 4 times!!',\n",
              " 'Need to finalize the demo Dogpus which will be used for rhia goteH8ok and it Cnould be done Do(n! !. It should be FIne by the ending of this month. But w(.l it? TJiE no%eflok has ge#n run 4 times!!',\n",
              " 'Need to finalize the demo corpus 1hicY wkli be used for this nltdgook and it sh*Kld be voJe AooJ! !. It should be done by the ending of Guis m(hth. But will it? ThkC notebook has be3j run 4 times!!',\n",
              " 'Nf3d to finakiS# the demo foGpus which will be uWer for thlq notebook and it should be done soon! !. It shPJld be done by the rnving of this momtm. But w&Pl it? This notebook has heSn run 4 times!!',\n",
              " 'Need to finalize the de,( corpus which wkol be  TsWd for %hks bPtSbook and it shokKd be done dooH! !. It should be done by the ending of this monyy. But will it? This no%ebkoM has VeDn run 4 times!!',\n",
              " 'Need to finalize the feho corpus which wOIl be usFc for rhJs nLtego*k and it sh8uPd be done soon! !. It should be done by the ending of this m8n4h. But will it? 5Nis n0teboIo has bWej run 4 times!!',\n",
              " 'Need to fLnalix$ the demo corpus whUvh will be kseE for Fhie notebook and it Zhoulc be dlGe soon! !. It sh)ulC be done by the end9nT of this month. But will it? This notebook has bS#n run 4 ^7mes!!',\n",
              " 'MeeV to finalize the demo cPrp7s which q&ll be KsDd for this notebook and it should be done soon! !. It dhoulE be done by the ending of tgiA month. But 1ilI it? 6hLs hoYebokk has been run 4 tim#d!!',\n",
              " 'HDed to finalize the wwmo Xorp*s which will be Hsec for tJiZ notebook and it shou.C be done spIn! !. It should be d)nf by the ending of tyLs month. But @7ll it? This notebook has been run 4 times!!',\n",
              " 'Need to finalize the demo FIrpus which #8ll be used for tBiQ no6eb9)k and it sGoKld be done do9n! !. It shou;R be dIme by the eGdJng of this month. But will it? This notebook has been run 4 ti<@s!!',\n",
              " 'Need to fLnsl7ze the demo corpus which will be used for this not#boKl and it should be d9He siKn! !. It sToIld be done by the ejdkng of this m(bth. But sJll it? This notebook has bewJ run 4 tLmeX!!',\n",
              " 'JeeC to finalize the demo vo$pus wJ7ch w*lk be udex for yBis notebook and it should be done soon! !. It should be done by the ending of this nonyh. But wiiI it? Rhiw Jotefo9k has been run 4 times!!',\n",
              " 'NewW to final8xf the demo corpus wm*ch wJlp be uc2d for hhiW notebook and it should be done c9on! !. It should be done by the ebEing of this month. But will it? This notebook has bFeB run 4 tom$s!!',\n",
              " 'Need to fimal9ae the dDmp corpjA Qhifh w(Kl be used for this no%ebo)j and it should be done EooH! !. It sgoHld be done by the eHdinT of this momRh. But will it? This notebook has been run 4 times!!',\n",
              " 'Gerd to finalize the demo corpus which wjlo be us@e for this notebook and it Zhkuld be d0Je Zoog! !. It should be done by the enxung of rhiQ month. But will it? 4h9s notebook has b4$n run 4 times!!',\n",
              " 'Need to finalize the dej8 corpus which w7lK be usFX for this notebook and it should be done soon! !. It sgouls be d9He by the ending of fh7s monRu. But !9ll it? Rhid notebook has HSen run 4 times!!',\n",
              " 'Need to finalize the demo Vorp Ts 1hicU will be used for this noteb(lm and it smouId be done sokG! !. It should be done by the enC&ng of th(w <obth. But w(l. it? This notebook has bfeb run 4 times!!',\n",
              " 'Need to finalize the demo corpus which will be uswr for tgJs noteHLpk and it should be d9me soon! !. It cho8ld be done by the ending of this mIbth. But wi,> it? TNUs hoteblol has b4eH run 4 times!!']"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mWp9OxOHDm2_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}