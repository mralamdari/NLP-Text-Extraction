{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-Auto-Complete-Beginner.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPrCEZXzDyJ79knRKOpw29u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mr-alamdari/NLP-Auto-Complete-Beginner/blob/main/NLP_Auto_Complete_Beginner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ENDB9Zw7jXXj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ec1432d-2338-42b9-b8c2-22b9902a2c42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U trax\n",
        "\n",
        "import trax\n",
        "\n",
        "# import trax.fastmath.numpy as np\n",
        "\n",
        "from trax import layers as tl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlB_5UqLk78I",
        "outputId": "f9ee2294-58a6-4385-9956-8d36ab145a11"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 637 kB 8.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 56.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 53.9 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/amanjeetsahu/Natural-Language-Processing-Specialization/master/Natural%20Language%20Processing%20with%20Probabilistic%20Models/Week%203/en_US.twitter.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8a_B5GekswL",
        "outputId": "5e951f62-b2c6-4c4e-e4f8-07af5f740749"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-25 17:27:30--  https://raw.githubusercontent.com/amanjeetsahu/Natural-Language-Processing-Specialization/master/Natural%20Language%20Processing%20with%20Probabilistic%20Models/Week%203/en_US.twitter.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3341555 (3.2M) [text/plain]\n",
            "Saving to: ‘en_US.twitter.txt’\n",
            "\n",
            "en_US.twitter.txt   100%[===================>]   3.19M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2022-04-25 17:27:30 (60.8 MB/s) - ‘en_US.twitter.txt’ saved [3341555/3341555]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('en_US.twitter.txt', 'r') as f:\n",
        "  data = f.read()"
      ],
      "metadata": {
        "id": "htKmLHwTlH0p"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(data), type(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1E_qzSoMlfv6",
        "outputId": "37c9a8d8-67b8-4e8d-96d2-3029f5cf62f0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3335477 <class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(data[0:400])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "3x1JiEiklQwC",
        "outputId": "bf96e7ed-75dc-47d4-c34b-b713ae13c638"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"How are you? Btw thanks for the RT. You gonna be in DC anytime soon? Love to see you. Been way, way too long.\\nWhen you meet someone special... you'll know. Your heart will beat more rapidly and you'll smile for no reason.\\nthey've decided its more fun if I don't.\\nSo Tired D; Played Lazer Tag & Ran A LOT D; Ughh Going To Sleep Like In 5 Minutes ;)\\nWords from a complete stranger! Made my birthday eve\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(data[-400:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "pijZ4lAmlXhk",
        "outputId": "9deea765-43d2-472c-e232-0eadc81ec9f5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\"tplace jerks off aristocrats until they finally die in the midst of self-love.\\n's icon is life.\\nwe just had one a few weeks back....hopefully we will be back soon! wish you the best yo\\nColombia is with an 'o'...“: We now ship to 4 countries in South America (fist pump). Please welcome Columbia to the Stunner Family”\\n#GutsiestMovesYouCanMake Giving a cat a bath.\\nCoffee after 5 was a TERRIBLE idea.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split2Sentences(data):\n",
        "  \n",
        "  sentences = data.split('\\n')\n",
        "  sentences = [s.strip() for s in sentences]\n",
        "  sentences = [s for s in sentences if len(s)>0]\n",
        "  return sentences"
      ],
      "metadata": {
        "id": "IrNi900Slcpd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = split2Sentences(data)\n",
        "sentences[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8xNBFkFmLwf",
        "outputId": "c3b16a2e-61b0-46b2-dca5-c19514c7bf9f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['How are you? Btw thanks for the RT. You gonna be in DC anytime soon? Love to see you. Been way, way too long.',\n",
              " \"When you meet someone special... you'll know. Your heart will beat more rapidly and you'll smile for no reason.\",\n",
              " \"they've decided its more fun if I don't.\",\n",
              " 'So Tired D; Played Lazer Tag & Ran A LOT D; Ughh Going To Sleep Like In 5 Minutes ;)',\n",
              " 'Words from a complete stranger! Made my birthday even better :)',\n",
              " 'First Cubs game ever! Wrigley field is gorgeous. This is perfect. Go Cubs Go!',\n",
              " 'i no! i get another day off from skool due to the wonderful snow (: and THIS wakes me up...damn thing',\n",
              " \"I'm coo... Jus at work hella tired r u ever in cali\",\n",
              " 'The new sundrop commercial ...hehe love at first sight',\n",
              " 'we need to reconnect THIS WEEK']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.word_tokenize(sentences[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRr3KCGGnhQL",
        "outputId": "5ce3d6af-50c3-4154-abe9-bd7d1a342347"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['they', \"'ve\", 'decided', 'its', 'more', 'fun', 'if', 'I', 'do', \"n't\", '.']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.word_tokenize(sentences[20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JIvun4twnUe",
        "outputId": "3eb1a359-2258-478a-d710-8ba555143d00"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['“',\n",
              " ':',\n",
              " '``',\n",
              " 'The',\n",
              " 'tragedy',\n",
              " 'of',\n",
              " 'life',\n",
              " 'is',\n",
              " 'not',\n",
              " 'that',\n",
              " 'it',\n",
              " 'ends',\n",
              " 'so',\n",
              " 'soon',\n",
              " ',',\n",
              " 'but',\n",
              " 'that',\n",
              " 'we',\n",
              " 'wait',\n",
              " 'so',\n",
              " 'long',\n",
              " 'to',\n",
              " 'begin',\n",
              " 'it',\n",
              " '.',\n",
              " \"''\",\n",
              " '-',\n",
              " 'W.M',\n",
              " '.',\n",
              " 'Lewis',\n",
              " '”']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize_sentences =lambda sentences: [nltk.word_tokenize(s.lower()) for s in sentences]"
      ],
      "metadata": {
        "id": "DCAGpCmfmUog"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentences = tokenize_sentences(sentences)"
      ],
      "metadata": {
        "id": "uPiGr44inmVZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSo0vmOb8hpF",
        "outputId": "1f68377a-e5d4-48d9-8192-07b20495e8e1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['how',\n",
              " 'are',\n",
              " 'you',\n",
              " '?',\n",
              " 'btw',\n",
              " 'thanks',\n",
              " 'for',\n",
              " 'the',\n",
              " 'rt',\n",
              " '.',\n",
              " 'you',\n",
              " 'gon',\n",
              " 'na',\n",
              " 'be',\n",
              " 'in',\n",
              " 'dc',\n",
              " 'anytime',\n",
              " 'soon',\n",
              " '?',\n",
              " 'love',\n",
              " 'to',\n",
              " 'see',\n",
              " 'you',\n",
              " '.',\n",
              " 'been',\n",
              " 'way',\n",
              " ',',\n",
              " 'way',\n",
              " 'too',\n",
              " 'long',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentences[20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-WBUm7GwryP",
        "outputId": "defadf69-3aee-4bba-c985-50bb0ccdd39a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['“',\n",
              " ':',\n",
              " '``',\n",
              " 'the',\n",
              " 'tragedy',\n",
              " 'of',\n",
              " 'life',\n",
              " 'is',\n",
              " 'not',\n",
              " 'that',\n",
              " 'it',\n",
              " 'ends',\n",
              " 'so',\n",
              " 'soon',\n",
              " ',',\n",
              " 'but',\n",
              " 'that',\n",
              " 'we',\n",
              " 'wait',\n",
              " 'so',\n",
              " 'long',\n",
              " 'to',\n",
              " 'begin',\n",
              " 'it',\n",
              " '.',\n",
              " \"''\",\n",
              " '-',\n",
              " 'w.m',\n",
              " '.',\n",
              " 'lewis',\n",
              " '”']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_tokenizer = lambda data: tokenize_sentences(split2Sentences(data))"
      ],
      "metadata": {
        "id": "I4MZmx8JoQQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentences = data_tokenizer(data)"
      ],
      "metadata": {
        "id": "0XPyCudFxOTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.shuffle(tokenized_sentences)\n",
        "train_size = int(len(tokenized_sentences)*0.8)\n",
        "train_data, test_data = tokenized_sentences[:train_size], tokenized_sentences[train_size:]"
      ],
      "metadata": {
        "id": "GkH6RpC1xPbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data), len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5asI24NxpOl",
        "outputId": "17da7d73-8a63-4880-aca4-f247e4f5e4c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38368 9593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def word_counter(tokenized_sentences):\n",
        "  word_dic = {}\n",
        "  for sentence in tokenized_sentences:\n",
        "    for token in sentence:\n",
        "      if token not in word_dic:\n",
        "        word_dic[token] = 1\n",
        "      else:\n",
        "        word_dic[token] += 1\n",
        "  return word_dic\n",
        "  # return collections.Counter(tokenized_sentences)"
      ],
      "metadata": {
        "id": "rf1wMIv3xq88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_c = word_counter(tokenized_sentences)\n",
        "\n",
        "for i, w in enumerate(word_c):\n",
        "  if i == 20:\n",
        "    break\n",
        "\n",
        "  print(w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72STa6R7yo2l",
        "outputId": "9561c451-c92b-426d-d143-b368c7433996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "crate\n",
            "and\n",
            "barrel\n",
            "?\n",
            "girl\n",
            ",\n",
            "i\n",
            "'ve\n",
            "been\n",
            "on\n",
            "etsy\n",
            "since\n",
            "yesterday\n",
            ".\n",
            "this\n",
            "stupid\n",
            "website\n",
            "is\n",
            "spammin\n",
            "all\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def words_with_nplus_frequncy(tokenize_sentences, count_threshold):\n",
        "  closed_vocab = []\n",
        "  word_count = word_counter(tokenized_sentences)\n",
        "  for k, v in word_count.items():\n",
        "    if v >= count_threshold:\n",
        "      closed_vocab.append(k)\n",
        "  return closed_vocab"
      ],
      "metadata": {
        "id": "U4O96FuUysCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "closed_vocab = words_with_nplus_frequncy(tokenized_sentences,2)"
      ],
      "metadata": {
        "id": "jS-dhelOywvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "closed_vocab[: 20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TKo-pP10xMs",
        "outputId": "6e38482e-1d8f-4894-e94a-f3e47351fc68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['crate',\n",
              " 'and',\n",
              " 'barrel',\n",
              " '?',\n",
              " 'girl',\n",
              " ',',\n",
              " 'i',\n",
              " \"'ve\",\n",
              " 'been',\n",
              " 'on',\n",
              " 'etsy',\n",
              " 'since',\n",
              " 'yesterday',\n",
              " '.',\n",
              " 'this',\n",
              " 'stupid',\n",
              " 'website',\n",
              " 'is',\n",
              " 'all',\n",
              " 'of']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def oov2Unk(tokenized_data, vocab, unknown_token='<unk>'):\n",
        "  vocab = set(vocab)\n",
        "\n",
        "  replaced_tokenized_sentences = []\n",
        "  for i, sentence in enumerate(tokenized_data):\n",
        "\n",
        "    replace_sentences = []\n",
        "    for token in sentence:\n",
        "\n",
        "      temp_token = token if token in vocab else unknown_token\n",
        "      replace_sentences.append(temp_token)\n",
        "    replaced_tokenized_sentences.append(replace_sentences)\n",
        "  return replaced_tokenized_sentences"
      ],
      "metadata": {
        "id": "utdnWExn1ZnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(train_data, test_data, count_threshol=2):\n",
        "  \n",
        "  vocab = words_with_nplus_frequncy(train_data, count_threshol)\n",
        "  train_data_replaced = oov2Unk(train_data, vocab)\n",
        "  test_data_replaced = oov2Unk(test_data, vocab)\n",
        "  return train_data_replaced, test_data_replaced, vocab"
      ],
      "metadata": {
        "id": "HPIU4FiZ7xa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_replaced, test_data_replaced, vocab = preprocess_data(train_data, test_data)"
      ],
      "metadata": {
        "id": "Zmq3O4i63wII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_replaced[20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7lekEL_EP1v",
        "outputId": "3167556a-77c8-4430-a4e5-921e814c3df9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['we',\n",
              " 'offer',\n",
              " 'a',\n",
              " 'free',\n",
              " 'market',\n",
              " 'approach',\n",
              " 'to',\n",
              " 'success',\n",
              " 'in',\n",
              " 'the',\n",
              " 'music',\n",
              " 'industry',\n",
              " '!',\n",
              " '!']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_replaced[20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGruuQz8Ebkv",
        "outputId": "a86d1a76-04d6-45d5-c6cc-6834ebecf02c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['wow',\n",
              " 'i',\n",
              " 'really',\n",
              " 'wish',\n",
              " 'i',\n",
              " 'was',\n",
              " 'back',\n",
              " 'in',\n",
              " 'high',\n",
              " 'school',\n",
              " 'right',\n",
              " 'now',\n",
              " '...',\n",
              " '..']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def creat_n_grams(data, n, start_token='<s>', end_token='<e>'):\n",
        "  n_grams = {}\n",
        "  for sentence in data:\n",
        "    sentence = [start_token]*n + sentence + [end_token]\n",
        "    sentence = tuple(sentence)\n",
        "    m = len(sentence) if n==1 else len(sentence)-1\n",
        "\n",
        "    for i in range(m):\n",
        "      n_gram = sentence[i: i+n]\n",
        "      if n_gram in n_grams.keys():\n",
        "        n_grams[n_gram] += 1\n",
        "      else:\n",
        "        n_grams[n_gram] = 1\n",
        "  return n_grams"
      ],
      "metadata": {
        "id": "i9tL8e9cEg-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in creat_n_grams(test_data_replaced, 1).items():\n",
        "  print(i)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rylwzPgEMF5l",
        "outputId": "36cca664-af6c-4aa3-9dfe-9637826ee794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(('<s>',), 9593)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "creat_n_grams(test_data_replaced, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fhG5FUTMN6J",
        "outputId": "9357c6cb-a988-4890-c9b6-308394c00eac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('<s>',): 9593,\n",
              " ('yo',): 26,\n",
              " ('i',): 3647,\n",
              " (\"'m\",): 526,\n",
              " ('serious',): 12,\n",
              " ('following',): 51,\n",
              " ('the',): 3877,\n",
              " ('next',): 133,\n",
              " ('10.',): 2,\n",
              " ('as',): 276,\n",
              " ('long',): 74,\n",
              " ('u',): 322,\n",
              " ('ai',): 19,\n",
              " (\"n't\",): 855,\n",
              " ('that',): 1129,\n",
              " ('<unk>',): 5106,\n",
              " ('shit',): 69,\n",
              " ('...',): 1090,\n",
              " ('.',): 5936,\n",
              " ('let',): 170,\n",
              " (\"'s\",): 1233,\n",
              " ('be',): 795,\n",
              " ('real',): 61,\n",
              " ('bro..',): 1,\n",
              " ('<e>',): 9593,\n",
              " ('lobster',): 2,\n",
              " ('&',): 419,\n",
              " ('shrimp',): 3,\n",
              " ('with',): 698,\n",
              " ('a',): 2440,\n",
              " ('suit',): 4,\n",
              " ('on',): 1091,\n",
              " ('today',): 305,\n",
              " ('is',): 1567,\n",
              " ('feast',): 4,\n",
              " ('day',): 378,\n",
              " ('of',): 1450,\n",
              " ('st',): 6,\n",
              " ('mark',): 6,\n",
              " ('evangelist',): 1,\n",
              " ('will',): 403,\n",
              " ('visiting',): 7,\n",
              " ('his',): 130,\n",
              " ('church',): 13,\n",
              " ('in',): 1548,\n",
              " ('venice',): 2,\n",
              " ('less',): 25,\n",
              " ('than',): 115,\n",
              " ('3',): 189,\n",
              " ('weeks',): 31,\n",
              " ('cheering',): 3,\n",
              " ('up',): 461,\n",
              " ('its',): 141,\n",
              " ('so',): 688,\n",
              " ('hard',): 67,\n",
              " ('to',): 3101,\n",
              " ('get',): 482,\n",
              " ('out',): 468,\n",
              " ('my',): 1173,\n",
              " ('bed',): 41,\n",
              " ('what',): 504,\n",
              " ('was',): 485,\n",
              " ('cj',): 2,\n",
              " ('watson',): 2,\n",
              " ('doing',): 99,\n",
              " ('?',): 1738,\n",
              " ('when',): 359,\n",
              " ('senior',): 9,\n",
              " ('year',): 92,\n",
              " ('come',): 164,\n",
              " ('ima',): 14,\n",
              " ('have',): 669,\n",
              " ('blast',): 8,\n",
              " ('anyone',): 76,\n",
              " ('best',): 176,\n",
              " ('practices',): 3,\n",
              " ('or',): 275,\n",
              " ('guidelines',): 1,\n",
              " ('for',): 1576,\n",
              " ('implementing',): 2,\n",
              " ('an',): 289,\n",
              " ('institutional',): 1,\n",
              " ('repository',): 1,\n",
              " ('we',): 677,\n",
              " ('are',): 685,\n",
              " ('just',): 564,\n",
              " ('getting',): 103,\n",
              " ('started',): 29,\n",
              " ('ours',): 5,\n",
              " ('how',): 321,\n",
              " ('could',): 113,\n",
              " ('dislike',): 4,\n",
              " ('dirk',): 3,\n",
              " ('she',): 157,\n",
              " ('got',): 244,\n",
              " ('da',): 20,\n",
              " ('body',): 13,\n",
              " ('!',): 5250,\n",
              " ('(',): 368,\n",
              " ('some',): 233,\n",
              " ('tunes',): 5,\n",
              " (')',): 842,\n",
              " ('taking',): 28,\n",
              " ('huge',): 22,\n",
              " ('test',): 13,\n",
              " ('wish',): 110,\n",
              " ('me',): 831,\n",
              " ('luck',): 37,\n",
              " ('xx',): 8,\n",
              " ('vote',): 18,\n",
              " ('pink',): 7,\n",
              " ('wig',): 3,\n",
              " ('and',): 1761,\n",
              " (',',): 3007,\n",
              " ('you',): 2409,\n",
              " ('brave',): 1,\n",
              " ('smart',): 12,\n",
              " ('girl',): 59,\n",
              " ('it',): 1574,\n",
              " ('going',): 230,\n",
              " ('grow',): 11,\n",
              " ('back',): 259,\n",
              " (\"'re\",): 251,\n",
              " ('teach',): 5,\n",
              " ('us',): 209,\n",
              " ('casting',): 4,\n",
              " ('new',): 288,\n",
              " ('reality',): 10,\n",
              " ('show',): 148,\n",
              " ('friend',): 71,\n",
              " ('relationship',): 14,\n",
              " ('email',): 27,\n",
              " ('your',): 672,\n",
              " ('story',): 32,\n",
              " (':',): 1591,\n",
              " ('good',): 415,\n",
              " ('far',): 46,\n",
              " (\"'ll\",): 227,\n",
              " ('radio',): 24,\n",
              " ('chili',): 7,\n",
              " ('at',): 768,\n",
              " ('9',): 20,\n",
              " ('pm',): 19,\n",
              " ('do',): 752,\n",
              " ('2',): 151,\n",
              " ('different',): 32,\n",
              " ('ones',): 19,\n",
              " ('question',): 26,\n",
              " ('like',): 513,\n",
              " ('asking',): 13,\n",
              " ('politicians',): 3,\n",
              " ('which',): 52,\n",
              " ('lesser',): 1,\n",
              " ('two',): 51,\n",
              " ('evils',): 2,\n",
              " ('damn',): 54,\n",
              " ('straight',): 17,\n",
              " ('remember',): 44,\n",
              " ('screaming',): 1,\n",
              " ('head',): 46,\n",
              " ('off',): 146,\n",
              " ('90',): 3,\n",
              " ('during',): 31,\n",
              " ('bills',): 7,\n",
              " ('playoff',): 5,\n",
              " ('games',): 35,\n",
              " ('saying',): 26,\n",
              " ('``',): 571,\n",
              " (\"''\",): 551,\n",
              " ('beast',): 4,\n",
              " ('lb',): 3,\n",
              " ('thanks',): 388,\n",
              " ('memories',): 7,\n",
              " ('once',): 44,\n",
              " ('tiger',): 5,\n",
              " ('always',): 113,\n",
              " ('rt',): 352,\n",
              " ('[',): 24,\n",
              " ('denver',): 15,\n",
              " ('news',): 39,\n",
              " (']',): 28,\n",
              " ('man',): 100,\n",
              " ('guilty',): 3,\n",
              " ('near',): 19,\n",
              " ('boulder',): 1,\n",
              " ('—',): 7,\n",
              " ('p',): 32,\n",
              " ('these',): 81,\n",
              " ('freshman',): 2,\n",
              " ('need',): 217,\n",
              " ('go',): 296,\n",
              " ('die',): 16,\n",
              " ('kicked',): 9,\n",
              " ('bus',): 22,\n",
              " ('5',): 47,\n",
              " ('minutes',): 23,\n",
              " ('made',): 74,\n",
              " ('jon',): 4,\n",
              " ('jones',): 10,\n",
              " ('look',): 126,\n",
              " ('human',): 11,\n",
              " ('then',): 141,\n",
              " ('stopped',): 7,\n",
              " ('min',): 12,\n",
              " ('had',): 160,\n",
              " ('against',): 19,\n",
              " ('jj',): 3,\n",
              " ('ended',): 8,\n",
              " ('wow',): 59,\n",
              " ('really',): 193,\n",
              " ('high',): 48,\n",
              " ('school',): 78,\n",
              " ('right',): 202,\n",
              " ('now',): 376,\n",
              " ('..',): 54,\n",
              " ('sometimes',): 39,\n",
              " ('walk',): 20,\n",
              " ('by',): 250,\n",
              " ('sea',): 7,\n",
              " (';',): 204,\n",
              " ('start',): 84,\n",
              " ('hearing',): 12,\n",
              " ('curse',): 5,\n",
              " ('words',): 31,\n",
              " ('mind',): 37,\n",
              " ('time',): 321,\n",
              " ('turn',): 24,\n",
              " ('plate',): 1,\n",
              " ('over',): 124,\n",
              " ('heading',): 18,\n",
              " ('check',): 73,\n",
              " ('improved',): 2,\n",
              " ('field',): 14,\n",
              " ('venue',): 5,\n",
              " ('sweet',): 41,\n",
              " ('haha',): 99,\n",
              " ('miss',): 72,\n",
              " (\"'d\",): 63,\n",
              " ('but',): 474,\n",
              " ('ca',): 200,\n",
              " ('find',): 65,\n",
              " ('ur',): 68,\n",
              " ('parent',): 3,\n",
              " ('makes',): 60,\n",
              " ('lyrics',): 6,\n",
              " ('favorite',): 58,\n",
              " ('song',): 46,\n",
              " ('they',): 299,\n",
              " ('can',): 414,\n",
              " ('try',): 49,\n",
              " ('sing',): 9,\n",
              " ('car',): 28,\n",
              " ('annoying',): 11,\n",
              " ('chapter',): 10,\n",
              " ('complete',): 6,\n",
              " ('info',): 28,\n",
              " ('sent',): 18,\n",
              " ('books',): 21,\n",
              " ('shelf',): 1,\n",
              " ('japan',): 3,\n",
              " ('mid-march',): 1,\n",
              " ('all',): 526,\n",
              " ('livin',): 3,\n",
              " ('n',): 39,\n",
              " ('black',): 39,\n",
              " ('hole',): 10,\n",
              " ('way',): 149,\n",
              " ('light',): 26,\n",
              " ('often',): 12,\n",
              " ('upon',): 4,\n",
              " ('rotten',): 2,\n",
              " ('pumpkins',): 1,\n",
              " ('forest',): 2,\n",
              " ('animals',): 6,\n",
              " ('interactive',): 2,\n",
              " ('ads',): 4,\n",
              " ('perfect',): 33,\n",
              " ('placement',): 1,\n",
              " ('kick',): 9,\n",
              " ('doors',): 8,\n",
              " ('down',): 120,\n",
              " ('ipad',): 14,\n",
              " ('tablet',): 1,\n",
              " ('advertising',): 2,\n",
              " ('world',): 74,\n",
              " ('results',): 8,\n",
              " ('ready',): 71,\n",
              " ('letter',): 6,\n",
              " ('coordinator',): 1,\n",
              " ('re',): 16,\n",
              " ('#',): 1092,\n",
              " ('first',): 135,\n",
              " ('sentence',): 3,\n",
              " ('this',): 645,\n",
              " ('thread',): 1,\n",
              " ('completely',): 13,\n",
              " ('useless',): 3,\n",
              " ('snap',): 5,\n",
              " ('tell',): 89,\n",
              " ('momma',): 4,\n",
              " ('thur',): 1,\n",
              " ('not',): 472,\n",
              " ('any',): 106,\n",
              " ('other',): 72,\n",
              " ('missing',): 14,\n",
              " ('lacking',): 1,\n",
              " ('motivation',): 7,\n",
              " ('tryna',): 7,\n",
              " ('see',): 272,\n",
              " ('tonight',): 215,\n",
              " ('looks',): 53,\n",
              " ('gon',): 82,\n",
              " ('na',): 157,\n",
              " ('b',): 33,\n",
              " ('great',): 312,\n",
              " ('thefirstsongiheardby',): 1,\n",
              " ('kid',): 18,\n",
              " ('ink',): 3,\n",
              " ('sending',): 9,\n",
              " ('questions',): 13,\n",
              " ('artists',): 4,\n",
              " ('aj',): 1,\n",
              " ('duh',): 7,\n",
              " ('chris',): 19,\n",
              " ('matthews',): 1,\n",
              " ('ripped',): 4,\n",
              " ('santorum',): 7,\n",
              " ('did',): 223,\n",
              " ('else',): 50,\n",
              " ('notice',): 9,\n",
              " ('dude',): 25,\n",
              " (\"'\",): 130,\n",
              " ('video',): 42,\n",
              " ('wearing',): 18,\n",
              " ('bieber',): 9,\n",
              " ('sweater',): 3,\n",
              " ('lol',): 270,\n",
              " ('where',): 125,\n",
              " ('ever',): 99,\n",
              " ('artful',): 1,\n",
              " ('tattoo',): 7,\n",
              " ('cure',): 2,\n",
              " ('support',): 41,\n",
              " ('cures',): 2,\n",
              " ('cancer',): 9,\n",
              " ('earrings',): 1,\n",
              " ('simplicity',): 2,\n",
              " ('form',): 7,\n",
              " ('sophistication',): 1,\n",
              " ('girls',): 30,\n",
              " ('golf',): 5,\n",
              " ('wilsonville',): 3,\n",
              " ('lee',): 4,\n",
              " ('wins',): 15,\n",
              " ('individual',): 5,\n",
              " ('league',): 7,\n",
              " ('title',): 14,\n",
              " ('mike',): 12,\n",
              " ('coach',): 14,\n",
              " ('well',): 156,\n",
              " (\"'ve\",): 124,\n",
              " ('never',): 130,\n",
              " ('seen',): 33,\n",
              " ('use',): 68,\n",
              " ('ijs',): 2,\n",
              " ('before',): 75,\n",
              " ('even',): 99,\n",
              " ('convinced',): 4,\n",
              " ('people',): 220,\n",
              " ('hate',): 83,\n",
              " ('pants',): 16,\n",
              " ('omg',): 38,\n",
              " ('dont',): 55,\n",
              " ('shy',): 2,\n",
              " ('away',): 53,\n",
              " ('from',): 332,\n",
              " ('bringing',): 8,\n",
              " ('camera',): 10,\n",
              " ('play',): 71,\n",
              " ('saw',): 63,\n",
              " ('pics',): 13,\n",
              " ('facebook',): 38,\n",
              " ('dance',): 23,\n",
              " ('studios',): 2,\n",
              " ('adventures',): 3,\n",
              " ('costume',): 4,\n",
              " ('fittings',): 1,\n",
              " ('guys',): 99,\n",
              " ('warner',): 1,\n",
              " ('chan',): 2,\n",
              " ('36',): 1,\n",
              " ('interviewed',): 3,\n",
              " ('cataloging',): 1,\n",
              " ('rules',): 9,\n",
              " ('want',): 184,\n",
              " ('glad',): 64,\n",
              " ('apart',): 5,\n",
              " ('if',): 455,\n",
              " ('something',): 85,\n",
              " ('simple',): 7,\n",
              " ('garage',): 3,\n",
              " ('band',): 26,\n",
              " ('set',): 26,\n",
              " ('voice',): 21,\n",
              " ('hit',): 33,\n",
              " ('record',): 14,\n",
              " ('much',): 170,\n",
              " ('wonder',): 21,\n",
              " ('who',): 251,\n",
              " ('riding',): 5,\n",
              " ('wit',): 20,\n",
              " ('tmrw',): 3,\n",
              " ('kennywood',): 2,\n",
              " ('gabe',): 2,\n",
              " ('wants',): 29,\n",
              " ('know',): 317,\n",
              " ('post',): 40,\n",
              " ('speaking',): 15,\n",
              " ('tried',): 14,\n",
              " ('dish',): 4,\n",
              " ('lots',): 19,\n",
              " ('hawks',): 4,\n",
              " ('only',): 154,\n",
              " ('farm',): 2,\n",
              " ('our',): 238,\n",
              " ('chickens',): 1,\n",
              " ('no',): 326,\n",
              " ('el',): 6,\n",
              " ('de',): 15,\n",
              " ('one',): 335,\n",
              " ('bit',): 30,\n",
              " ('heavy',): 5,\n",
              " ('heart',): 35,\n",
              " ('knowing',): 11,\n",
              " ('wont',): 16,\n",
              " ('there',): 321,\n",
              " ('home',): 104,\n",
              " ('tonight..',): 3,\n",
              " ('true',): 38,\n",
              " ('desperate',): 4,\n",
              " ('nap',): 15,\n",
              " ('house',): 59,\n",
              " ('her',): 156,\n",
              " ('prom',): 6,\n",
              " ('wake',): 20,\n",
              " ('too',): 243,\n",
              " ('“',): 131,\n",
              " ('wonderful',): 26,\n",
              " ('hey',): 112,\n",
              " ('wee',): 1,\n",
              " ('”',): 125,\n",
              " ('everyonehasthat1friend',): 3,\n",
              " ('maid',): 2,\n",
              " ('honor',): 7,\n",
              " ('party',): 45,\n",
              " ('underway',): 3,\n",
              " ('tweeting',): 22,\n",
              " ('winners',): 4,\n",
              " ('years',): 55,\n",
              " ('starting',): 20,\n",
              " ('soon',): 74,\n",
              " ('traps',): 2,\n",
              " ('sore',): 3,\n",
              " ('fuck',): 49,\n",
              " ('tuesday',): 23,\n",
              " ('s',): 39,\n",
              " ('looking',): 129,\n",
              " ('forward',): 60,\n",
              " ('seeing',): 31,\n",
              " ('happy',): 204,\n",
              " ('nc',): 6,\n",
              " ('folk',): 2,\n",
              " ('--',): 90,\n",
              " ('raleigh',): 2,\n",
              " ('around',): 56,\n",
              " ('march',): 18,\n",
              " ('15',): 21,\n",
              " ('until',): 47,\n",
              " ('least',): 35,\n",
              " ('august',): 6,\n",
              " ('breather',): 1,\n",
              " ('spring',): 20,\n",
              " ('quarter',): 6,\n",
              " ('hang',): 16,\n",
              " ('headed',): 12,\n",
              " ('awesomeness',): 2,\n",
              " ('expected',): 1,\n",
              " ('appreciate',): 20,\n",
              " ('passion',): 6,\n",
              " ('court',): 9,\n",
              " ('law',): 17,\n",
              " ('everyone',): 79,\n",
              " ('innocent',): 2,\n",
              " ('proven',): 1,\n",
              " ('call',): 77,\n",
              " ('valley',): 5,\n",
              " ('terrain',): 2,\n",
              " ('between',): 23,\n",
              " ('proof',): 5,\n",
              " ('concept',): 2,\n",
              " ('beginning',): 11,\n",
              " ('mass',): 3,\n",
              " ('production',): 6,\n",
              " ('significant',): 2,\n",
              " ('sales',): 8,\n",
              " ('thank',): 161,\n",
              " ('love',): 405,\n",
              " ('treat',): 9,\n",
              " ('princess',): 2,\n",
              " ('talk',): 59,\n",
              " ('make',): 181,\n",
              " ('💘',): 2,\n",
              " ('kiss',): 5,\n",
              " ('😘',): 1,\n",
              " ('mention',): 19,\n",
              " ('weekend',): 70,\n",
              " ('mother',): 30,\n",
              " ('moms',): 14,\n",
              " ('everywhere',): 5,\n",
              " ('especially',): 14,\n",
              " ('selfless',): 2,\n",
              " ('mom',): 45,\n",
              " ('danger',): 1,\n",
              " ('myself',): 40,\n",
              " ('crazy',): 54,\n",
              " ('train',): 10,\n",
              " ('roll',): 13,\n",
              " ('yes',): 107,\n",
              " ('shopping',): 14,\n",
              " ('c',): 27,\n",
              " ('odd',): 4,\n",
              " ('jobs',): 8,\n",
              " ('neighborhood',): 2,\n",
              " ('text',): 22,\n",
              " ('big',): 103,\n",
              " ('orchestra',): 2,\n",
              " ('50',): 16,\n",
              " ('cent',): 3,\n",
              " ('beer',): 23,\n",
              " ('til',): 17,\n",
              " ('close',): 20,\n",
              " ('cents',): 2,\n",
              " ('buys',): 3,\n",
              " ('pint',): 2,\n",
              " ('premium',): 3,\n",
              " ('mondays',): 4,\n",
              " ('nights',): 8,\n",
              " ('diet',): 7,\n",
              " ('mountain',): 2,\n",
              " ('dew',): 1,\n",
              " ('tastes',): 5,\n",
              " ('pure',): 8,\n",
              " ('ass',): 52,\n",
              " ('wan',): 74,\n",
              " ('tinychat',): 2,\n",
              " ('tis',): 3,\n",
              " ('meeting',): 32,\n",
              " ('iso',): 1,\n",
              " ('executive',): 3,\n",
              " ('director',): 5,\n",
              " ('position',): 6,\n",
              " ('soon-to-be',): 1,\n",
              " ('unemployed',): 2,\n",
              " ('colleague',): 2,\n",
              " ('experience',): 14,\n",
              " ('level',): 11,\n",
              " ('hi',): 49,\n",
              " ('coming',): 58,\n",
              " ('actor',): 3,\n",
              " ('network',): 15,\n",
              " ('actors',): 5,\n",
              " ('mentor',): 3,\n",
              " ('business',): 48,\n",
              " ('fb',): 13,\n",
              " ('martin',): 10,\n",
              " ('fucking',): 35,\n",
              " ('boredom',): 3,\n",
              " ('someone',): 99,\n",
              " ('save',): 24,\n",
              " ('sleeping',): 6,\n",
              " ('into',): 90,\n",
              " ('every',): 91,\n",
              " ('night',): 147,\n",
              " ('pretend',): 5,\n",
              " ('dead',): 26,\n",
              " ('talks',): 6,\n",
              " ('about',): 379,\n",
              " ('important',): 11,\n",
              " ('decide',): 13,\n",
              " ('put',): 60,\n",
              " ('choices',): 6,\n",
              " ('quite',): 21,\n",
              " ('complicated',): 4,\n",
              " ('practice',): 12,\n",
              " ('houston',): 15,\n",
              " ('daughter',): 11,\n",
              " ('treated',): 2,\n",
              " ('released',): 9,\n",
              " ('la',): 37,\n",
              " ('hospital',): 8,\n",
              " ('stress',): 5,\n",
              " ('anxiety',): 4,\n",
              " ('still',): 160,\n",
              " ('tour',): 19,\n",
              " ('thought',): 66,\n",
              " ('said',): 65,\n",
              " ('whores',): 1,\n",
              " ('cares',): 7,\n",
              " ('ohh',): 4,\n",
              " ('why',): 161,\n",
              " ('heard',): 28,\n",
              " ('chillin',): 4,\n",
              " ('thats',): 28,\n",
              " ('son',): 23,\n",
              " ('football',): 24,\n",
              " ('redskins',): 2,\n",
              " ('cowboys',): 7,\n",
              " ('does',): 121,\n",
              " ('firm',): 2,\n",
              " ('strengths',): 1,\n",
              " ('expanding',): 3,\n",
              " ('relationships',): 4,\n",
              " ('pay',): 20,\n",
              " ('credit',): 7,\n",
              " ('hoping',): 9,\n",
              " ('skill',): 2,\n",
              " ('carries',): 2,\n",
              " ('wave',): 9,\n",
              " ('horizon',): 1,\n",
              " ('involved',): 7,\n",
              " ('organization',): 3,\n",
              " ('join',): 36,\n",
              " ('committee',): 6,\n",
              " ('plan',): 18,\n",
              " ('30th',): 4,\n",
              " ('anniv',): 1,\n",
              " ('event',): 35,\n",
              " ('anaheim',): 5,\n",
              " ('ft',): 5,\n",
              " ('reach',): 6,\n",
              " ('full',): 24,\n",
              " ('height',): 2,\n",
              " ('few',): 33,\n",
              " ('days',): 77,\n",
              " ('short',): 15,\n",
              " ('period',): 7,\n",
              " ('am',): 154,\n",
              " ('awake',): 5,\n",
              " ('😱',): 2,\n",
              " ('research',): 9,\n",
              " ('job',): 45,\n",
              " ('easily',): 5,\n",
              " ('summer',): 39,\n",
              " ('flag',): 3,\n",
              " ('spent',): 10,\n",
              " ('hour',): 35,\n",
              " ('cleaning',): 9,\n",
              " ('making',): 55,\n",
              " ('effort',): 7,\n",
              " ('tweet',): 74,\n",
              " ('more',): 252,\n",
              " ('stay',): 41,\n",
              " ('connected',): 1,\n",
              " ('niu',): 1,\n",
              " ('middle',): 13,\n",
              " ('watching',): 91,\n",
              " ('been',): 170,\n",
              " ('6',): 25,\n",
              " ('months',): 16,\n",
              " ('since',): 47,\n",
              " ('last',): 135,\n",
              " ('watched',): 22,\n",
              " ('blog',): 23,\n",
              " ('missed',): 22,\n",
              " ('❤',): 8,\n",
              " ('chase',): 12,\n",
              " ('town',): 28,\n",
              " ('parked',): 1,\n",
              " ('street',): 22,\n",
              " ('should',): 168,\n",
              " ('bedroom',): 3,\n",
              " ('wednesday',): 21,\n",
              " ('december',): 8,\n",
              " ('tuned',): 11,\n",
              " ('political',): 6,\n",
              " ('junkie',): 1,\n",
              " ('npr',): 2,\n",
              " ('ken',): 4,\n",
              " ('west',): 12,\n",
              " ('oct',): 4,\n",
              " ('4',): 66,\n",
              " ('landing',): 2,\n",
              " ('carmel',): 1,\n",
              " ('end',): 52,\n",
              " ('likely',): 9,\n",
              " ('here',): 158,\n",
              " ('stand',): 18,\n",
              " ('old',): 58,\n",
              " ('lose',): 25,\n",
              " ('wo',): 42,\n",
              " ('leave',): 25,\n",
              " ('mayor',): 2,\n",
              " ('stanton',): 2,\n",
              " ('announces',): 4,\n",
              " ('strike',): 3,\n",
              " ('phoenix',): 3,\n",
              " ('green',): 21,\n",
              " ('chamber',): 1,\n",
              " ('luncheon',): 3,\n",
              " ('-',): 366,\n",
              " ('afternoon',): 18,\n",
              " ('wishing',): 15,\n",
              " ('album',): 20,\n",
              " ('advocates',): 2,\n",
              " ('choice',): 10,\n",
              " ('women',): 23,\n",
              " ('conservative',): 1,\n",
              " ('choose',): 8,\n",
              " ('total',): 11,\n",
              " ('liberty',): 1,\n",
              " ('liberal',): 3,\n",
              " ('being',): 75,\n",
              " ('bound',): 6,\n",
              " ('regulation',): 2,\n",
              " ('hangin',): 2,\n",
              " ('everybody',): 23,\n",
              " ('little',): 70,\n",
              " ('park',): 17,\n",
              " ('recreation',): 1,\n",
              " ('watch',): 52,\n",
              " ('american',): 22,\n",
              " ('reunion',): 5,\n",
              " ('sister',): 23,\n",
              " ('sean',): 3,\n",
              " ('lololol',): 3,\n",
              " ('tx',): 3,\n",
              " ('loving',): 22,\n",
              " ('comments',): 10,\n",
              " ('work',): 163,\n",
              " ('smarter',): 2,\n",
              " ('harder',): 9,\n",
              " ('late',): 37,\n",
              " ('prove',): 5,\n",
              " ('pulling',): 3,\n",
              " ('weight',): 5,\n",
              " ('fez',): 1,\n",
              " ('everything',): 55,\n",
              " ('feels',): 22,\n",
              " ('fixed',): 9,\n",
              " ('changing',): 5,\n",
              " ('perspective',): 3,\n",
              " ('headache',): 4,\n",
              " ('mirror',): 2,\n",
              " ('sideways',): 2,\n",
              " ('definitely',): 18,\n",
              " ('fun',): 90,\n",
              " ('oh',): 148,\n",
              " ('please',): 130,\n",
              " ('follow',): 201,\n",
              " ('i.',): 4,\n",
              " ('possible',): 9,\n",
              " ('okc',): 4,\n",
              " ('fingers',): 9,\n",
              " ('sprained',): 2,\n",
              " ('finger',): 4,\n",
              " ('$',): 96,\n",
              " ('family',): 49,\n",
              " ('wat',): 9,\n",
              " ('r',): 46,\n",
              " ('takin',): 3,\n",
              " ('dim',): 1,\n",
              " ('mak',): 1,\n",
              " ('goals',): 9,\n",
              " ('punch',): 8,\n",
              " ('bro',): 39,\n",
              " ('sleep',): 47,\n",
              " ('chick',): 11,\n",
              " ('meet',): 47,\n",
              " ('nigga',): 11,\n",
              " ('trust',): 15,\n",
              " ('give',): 80,\n",
              " ('him',): 110,\n",
              " ('ex',): 9,\n",
              " ('sleepy',): 8,\n",
              " ('ta',): 32,\n",
              " ('thing',): 93,\n",
              " ('/',): 46,\n",
              " ('comment',): 14,\n",
              " ('picture',): 15,\n",
              " ('better',): 132,\n",
              " ('bitched',): 2,\n",
              " ('again',): 75,\n",
              " ('anything',): 48,\n",
              " ('drama',): 7,\n",
              " ('has',): 164,\n",
              " ('bad',): 82,\n",
              " ('tho',): 22,\n",
              " ('cause',): 44,\n",
              " ('think',): 204,\n",
              " ('understand',): 24,\n",
              " ('everythings',): 2,\n",
              " ('broken',): 8,\n",
              " ('obama',): 25,\n",
              " ('bomb',): 3,\n",
              " ('iran',): 3,\n",
              " ('discovered',): 4,\n",
              " ('north',): 13,\n",
              " ('hollywood',): 6,\n",
              " ('strip',): 2,\n",
              " ('clubs',): 3,\n",
              " ('utterly',): 1,\n",
              " ('worthless',): 3,\n",
              " ('im',): 113,\n",
              " ('soo',): 7,\n",
              " ('done',): 74,\n",
              " ('antm',): 1,\n",
              " ('funny',): 41,\n",
              " ('alot',): 12,\n",
              " ('won',): 23,\n",
              " ('learn',): 21,\n",
              " ('official',): 8,\n",
              " ('parade',): 6,\n",
              " ('line',): 24,\n",
              " ('counts',): 4,\n",
              " ('book',): 52,\n",
              " ('whole',): 35,\n",
              " ('wedding',): 9,\n",
              " ('garden',): 8,\n",
              " ('sponsors',): 5,\n",
              " ('blue',): 20,\n",
              " ('brewery',): 3,\n",
              " ('south',): 10,\n",
              " ('thursday',): 27,\n",
              " ('yet',): 44,\n",
              " ('freakn',): 3,\n",
              " ('anatomy',): 1,\n",
              " ('lab',): 2,\n",
              " ('unwanted',): 2,\n",
              " ('life',): 139,\n",
              " ('because',): 92,\n",
              " ('trying',): 51,\n",
              " ('sitting',): 17,\n",
              " ('2-0',): 1,\n",
              " ('runners',): 2,\n",
              " ('corners',): 2,\n",
              " ('0',): 6,\n",
              " ('outs',): 2,\n",
              " ('knew',): 20,\n",
              " ('game',): 92,\n",
              " ('would',): 218,\n",
              " ('liam',): 2,\n",
              " ('payne',): 1,\n",
              " ('uses',): 4,\n",
              " ('yanno',): 1,\n",
              " ('half',): 22,\n",
              " ('almost',): 33,\n",
              " ('forgot',): 13,\n",
              " ('friday',): 48,\n",
              " ('mos',): 1,\n",
              " ('wanted',): 24,\n",
              " ('crew',): 13,\n",
              " ('killed',): 14,\n",
              " ('netflix',): 4,\n",
              " ('blackberry',): 2,\n",
              " ('merger',): 2,\n",
              " ('equals',): 1,\n",
              " ('called',): 31,\n",
              " ('he',): 293,\n",
              " ('worth',): 22,\n",
              " ('obviously',): 10,\n",
              " ('<',): 230,\n",
              " ('/3',): 7,\n",
              " ('slip',): 4,\n",
              " ('topic',): 9,\n",
              " ('based',): 7,\n",
              " ('quote',): 8,\n",
              " ('open',): 45,\n",
              " ('each',): 18,\n",
              " ('lives',): 10,\n",
              " ('live',): 71,\n",
              " ('such',): 46,\n",
              " ('ghosts',): 1,\n",
              " ('compassionate',): 1,\n",
              " ('conservatives',): 2,\n",
              " ('young',): 24,\n",
              " ('hope',): 146,\n",
              " ('bang',): 2,\n",
              " ('shows',): 19,\n",
              " ('miller',): 5,\n",
              " ('jealous',): 16,\n",
              " ('andy',): 3,\n",
              " ('paul',): 15,\n",
              " ('fuller',): 3,\n",
              " ('yelled',): 1,\n",
              " ('lazy',): 5,\n",
              " ('believe',): 47,\n",
              " ('starter',): 3,\n",
              " ('talent',): 5,\n",
              " ('cowboy',): 3,\n",
              " ('fucken',): 3,\n",
              " ('wait',): 123,\n",
              " ('ran',): 5,\n",
              " ('blessing',): 2,\n",
              " ('morgan',): 2,\n",
              " ('joy',): 11,\n",
              " ('decisions',): 9,\n",
              " ('guess',): 48,\n",
              " ('problem',): 17,\n",
              " ('ride',): 17,\n",
              " ('tend',): 2,\n",
              " ('migrate',): 1,\n",
              " ('tomorrow',): 125,\n",
              " ('send',): 36,\n",
              " ('treatment',): 2,\n",
              " ('dm',): 29,\n",
              " ('emails',): 2,\n",
              " ('stephen',): 3,\n",
              " ('bell',): 4,\n",
              " ('references',): 2,\n",
              " ('kindle',): 6,\n",
              " ('project',): 26,\n",
              " ('university',): 12,\n",
              " ('textbooks',): 2,\n",
              " ('students',): 31,\n",
              " ('gave',): 22,\n",
              " ('thumbs',): 3,\n",
              " ('having',): 65,\n",
              " ('fellas',): 2,\n",
              " ('eating',): 11,\n",
              " ('egg',): 7,\n",
              " ('sandwich',): 5,\n",
              " ('while',): 59,\n",
              " ('menu',): 6,\n",
              " ('restaurant',): 13,\n",
              " ('buy',): 31,\n",
              " ('sell',): 12,\n",
              " ('amazon',): 1,\n",
              " ('takes',): 12,\n",
              " ('cut',): 17,\n",
              " ('paying',): 7,\n",
              " ('eco-friendly',): 1,\n",
              " ('though',): 61,\n",
              " ('sad',): 32,\n",
              " ('diffrent',): 1,\n",
              " ('bitch',): 26,\n",
              " ('loved',): 31,\n",
              " ('1',): 67,\n",
              " ('cheese',): 19,\n",
              " ('melt',): 1,\n",
              " ('eat',): 49,\n",
              " ('listen',): 22,\n",
              " ('very',): 88,\n",
              " ('music',): 88,\n",
              " ('hung',): 4,\n",
              " ('tweetdeck',): 1,\n",
              " ('crashes',): 1,\n",
              " ('frustrating',): 4,\n",
              " ('hootsuite',): 1,\n",
              " ('emailed',): 2,\n",
              " ('=',): 41,\n",
              " ('assume',): 3,\n",
              " ('flat',): 6,\n",
              " ('rented',): 1,\n",
              " ('festival',): 13,\n",
              " ('brilliant',): 11,\n",
              " ('kills',): 5,\n",
              " ('ff',): 17,\n",
              " ('bilingual',): 2,\n",
              " ('community',): 13,\n",
              " ('newspaper',): 2,\n",
              " ('produced',): 5,\n",
              " ('youth',): 4,\n",
              " ('por',): 2,\n",
              " ('y',): 11,\n",
              " ('para',): 1,\n",
              " ('needs',): 44,\n",
              " ('hush',): 3,\n",
              " ('help',): 75,\n",
              " ('fruit',): 5,\n",
              " ('yeah',): 89,\n",
              " ('lmao',): 24,\n",
              " ('comedy',): 3,\n",
              " ('also',): 69,\n",
              " ('sure',): 83,\n",
              " ('readers',): 2,\n",
              " ('thru',): 9,\n",
              " ('links',): 7,\n",
              " ('able',): 30,\n",
              " ('read',): 38,\n",
              " ('reached',): 5,\n",
              " ('their',): 113,\n",
              " ('limit',): 8,\n",
              " ('tummy',): 2,\n",
              " ('hurting',): 4,\n",
              " ('o',): 25,\n",
              " ('prolly',): 2,\n",
              " ('hungry',): 13,\n",
              " ('session',): 16,\n",
              " ('methods',): 3,\n",
              " ('aera2012',): 2,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in creat_n_grams(test_data_replaced, 2).items():\n",
        "  print(i)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MY475jgiMoaR",
        "outputId": "6bc02ca9-7279-4532-e30d-8616d8d45287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(('<s>', '<s>'), 9593)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def probability_calculator(word, previous_n_gram,n_gram_counts,n_plus1_gram_counts,vocab_size, k=1.0):\n",
        "\n",
        "  previous_n_gram = tuple(previous_n_gram)\n",
        "  previous_n_gram_counts = n_gram_counts[previous_n_gram] if previous_n_gram in n_gram_counts else 0\n",
        "  denominator = previous_n_gram_counts + k*vocab_size\n",
        "  n_plus1_gram = previous_n_gram + (word,)\n",
        "  n_plus1_gram_count = n_plus1_gram_counts[n_plus1_gram] if n_plus1_gram in n_plus1_gram_counts  else 0\n",
        "  numerator = n_plus1_gram_count + k\n",
        "  probability = numerator / denominator\n",
        "  return probability    "
      ],
      "metadata": {
        "id": "vv-NaQOZMo5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [['i', 'like', 'a', 'cat'],\n",
        "             ['this', 'dog', 'is', 'like', 'a', 'cat']]\n",
        "unique_words = list(set(sentences[0] + sentences[1]))\n",
        "\n",
        "unigram_counts = creat_n_grams(sentences, 1)\n",
        "bigram_counts = creat_n_grams(sentences, 2)\n",
        "tmp_prob = probability_calculator(\"cat\", \"a\", unigram_counts, bigram_counts, len(unique_words), k=1)"
      ],
      "metadata": {
        "id": "FDfEr3nnWPkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_prob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mISXkDzWcxv",
        "outputId": "7e472c91-bcac-42f3-b2dd-ec8c600f8601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3333333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_probabilities(previous_n_gram,n_gram_counts, n_plus1_gram_counts, vocab, k=1.0):\n",
        "\n",
        "  previous_n_gram = tuple(previous_n_gram)\n",
        "  vocab = vocab+['<e>', '<unk>']\n",
        "  vocab_size = len(vocab)\n",
        "\n",
        "  probabilities = {}\n",
        "  for word in vocab:\n",
        "    prob = probability_calculator(word, previous_n_gram,n_gram_counts, n_plus1_gram_counts, vocab_size, k=1.0)\n",
        "    probabilities[word] = prob\n",
        "  return probabilities"
      ],
      "metadata": {
        "id": "hWVjFaqcWegr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [['i', 'like', 'a', 'cat'],\n",
        "             ['this', 'dog', 'is', 'like', 'a', 'cat']]\n",
        "unique_words = list(set(sentences[0] + sentences[1]))\n",
        "\n",
        "unigram_counts = creat_n_grams(sentences, 1)\n",
        "bigram_counts = creat_n_grams(sentences, 2)\n",
        "estimate_probabilities(\"a\", unigram_counts, bigram_counts, unique_words, k=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOGRYCuJZEau",
        "outputId": "f48d586d-f6e7-483c-b06d-1d8a9987e131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<e>': 0.09090909090909091,\n",
              " '<unk>': 0.09090909090909091,\n",
              " 'a': 0.09090909090909091,\n",
              " 'cat': 0.2727272727272727,\n",
              " 'dog': 0.09090909090909091,\n",
              " 'i': 0.09090909090909091,\n",
              " 'is': 0.09090909090909091,\n",
              " 'like': 0.09090909090909091,\n",
              " 'this': 0.09090909090909091}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_matrix(n_plus1_gram_counts, vocab):\n",
        "  vocab = vocab + ['<e>', '<unk>']\n",
        "  n_grams = []\n",
        "  for n_plus1_gram in n_plus1_gram_counts.keys():\n",
        "    n_gram = n_plus1_gram[0: -1]\n",
        "    n_grams.append(n_gram)\n",
        "  n_grams = list(set(n_grams))\n",
        "\n",
        "  row_index = {n_gram: i for i, n_gram in enumerate(n_grams)}\n",
        "  col_index = {n_gram: j for j, n_gram in enumerate(vocab)}\n",
        "  row = len(n_grams)\n",
        "  col = len(vocab)\n",
        "  count_mat = np.zeros((row, col))\n",
        "\n",
        "  for n_plus1_gram, count in n_plus1_gram_counts.items():\n",
        "    n_gram  = n_plus1_gram[0: -1]\n",
        "    word = n_plus1_gram[-1]\n",
        "    if word not in vocab:\n",
        "      continue\n",
        "    i, j = row_index[n_gram], col_index[word]\n",
        "    count_mat[i, j] = count\n",
        "\n",
        "  count_dic = pd.DataFrame(count_mat, index=n_grams, columns=vocab)\n",
        "  return count_dic"
      ],
      "metadata": {
        "id": "rnkWYIYGZGJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [['i', 'like', 'a', 'cat'],\n",
        "                 ['this', 'dog', 'is', 'like', 'a', 'cat']]\n",
        "unique_words = list(set(sentences[0] + sentences[1]))\n",
        "bigram_counts = creat_n_grams(sentences, 2)\n",
        "\n",
        "print('unigram counts')\n",
        "display(count_matrix(bigram_counts, unique_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "9InRdRXf1Avz",
        "outputId": "93ef3316-b3a3-4884-fa79-baeca492c2b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unigram counts\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         like  cat  this  dog    i   is    a  <e>  <unk>\n",
              "(<s>,)    0.0  0.0   1.0  0.0  1.0  0.0  0.0  0.0    0.0\n",
              "(is,)     1.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0    0.0\n",
              "(a,)      0.0  2.0   0.0  0.0  0.0  0.0  0.0  0.0    0.0\n",
              "(like,)   0.0  0.0   0.0  0.0  0.0  0.0  2.0  0.0    0.0\n",
              "(dog,)    0.0  0.0   0.0  0.0  0.0  1.0  0.0  0.0    0.0\n",
              "(cat,)    0.0  0.0   0.0  0.0  0.0  0.0  0.0  2.0    0.0\n",
              "(this,)   0.0  0.0   0.0  1.0  0.0  0.0  0.0  0.0    0.0\n",
              "(i,)      1.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0    0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b884db6d-805f-4262-8f39-0a8afac41adf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>like</th>\n",
              "      <th>cat</th>\n",
              "      <th>this</th>\n",
              "      <th>dog</th>\n",
              "      <th>i</th>\n",
              "      <th>is</th>\n",
              "      <th>a</th>\n",
              "      <th>&lt;e&gt;</th>\n",
              "      <th>&lt;unk&gt;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>(&lt;s&gt;,)</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(is,)</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(a,)</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(like,)</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(dog,)</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(cat,)</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(this,)</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(i,)</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b884db6d-805f-4262-8f39-0a8afac41adf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b884db6d-805f-4262-8f39-0a8afac41adf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b884db6d-805f-4262-8f39-0a8afac41adf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def probability_matrix(n_plus1_gram_counts, vocab, k):\n",
        "  count_mat = count_matrix(n_plus1_gram_counts, vocab)\n",
        "  count_mat += k\n",
        "  prob_mat = count_mat.div(np.sum(count_mat, axis=1), axis=0)\n",
        "  return prob_mat"
      ],
      "metadata": {
        "id": "1RtYF_zf2Rdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probability_matrix(bigram_counts, unique_words, k=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "W0d2CzX43eKn",
        "outputId": "7ab97613-34f0-40be-94c1-6f51f639a769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             like       cat      this       dog         i        is         a  \\\n",
              "(<s>,)   0.090909  0.090909  0.181818  0.090909  0.181818  0.090909  0.090909   \n",
              "(is,)    0.200000  0.100000  0.100000  0.100000  0.100000  0.100000  0.100000   \n",
              "(a,)     0.090909  0.272727  0.090909  0.090909  0.090909  0.090909  0.090909   \n",
              "(like,)  0.090909  0.090909  0.090909  0.090909  0.090909  0.090909  0.272727   \n",
              "(dog,)   0.100000  0.100000  0.100000  0.100000  0.100000  0.200000  0.100000   \n",
              "(cat,)   0.090909  0.090909  0.090909  0.090909  0.090909  0.090909  0.090909   \n",
              "(this,)  0.100000  0.100000  0.100000  0.200000  0.100000  0.100000  0.100000   \n",
              "(i,)     0.200000  0.100000  0.100000  0.100000  0.100000  0.100000  0.100000   \n",
              "\n",
              "              <e>     <unk>  \n",
              "(<s>,)   0.090909  0.090909  \n",
              "(is,)    0.100000  0.100000  \n",
              "(a,)     0.090909  0.090909  \n",
              "(like,)  0.090909  0.090909  \n",
              "(dog,)   0.100000  0.100000  \n",
              "(cat,)   0.272727  0.090909  \n",
              "(this,)  0.100000  0.100000  \n",
              "(i,)     0.100000  0.100000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-928d4086-e512-42a3-bbf1-e731cfdd67ee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>like</th>\n",
              "      <th>cat</th>\n",
              "      <th>this</th>\n",
              "      <th>dog</th>\n",
              "      <th>i</th>\n",
              "      <th>is</th>\n",
              "      <th>a</th>\n",
              "      <th>&lt;e&gt;</th>\n",
              "      <th>&lt;unk&gt;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>(&lt;s&gt;,)</th>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(is,)</th>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(a,)</th>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(like,)</th>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(dog,)</th>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(cat,)</th>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.090909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(this,)</th>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>(i,)</th>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-928d4086-e512-42a3-bbf1-e731cfdd67ee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-928d4086-e512-42a3-bbf1-e731cfdd67ee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-928d4086-e512-42a3-bbf1-e731cfdd67ee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def perplexity(sentence, n_gram_counts, n_plus1_gram_counts, vocab_size, k=1):\n",
        "\n",
        "  n = len(list(n_gram_counts.keys())[0])\n",
        "  sentence = ['<s>'] * n + sentence + ['<e>']\n",
        "  sentence = tuple(sentence)\n",
        "  N = len(sentence)\n",
        "  product_pi = 1.0\n",
        "\n",
        "  for i in range(n, N):\n",
        "    n_gram = sentence[i-n: i]\n",
        "    word = sentence[i]\n",
        "    probability = probability_calculator(word, n_gram, n_gram_counts, n_plus1_gram_counts,vocab_size, k)\n",
        "    product_pi /= probability\n",
        "  \n",
        "  perplexity_value = product_pi ** (1/N)\n",
        "  return perplexity_value"
      ],
      "metadata": {
        "id": "-obYu_H430ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [['i', 'like', 'a', 'cat'],\n",
        "                 ['this', 'dog', 'is', 'like', 'a', 'cat']]\n",
        "\n",
        "perplexity_value = perplexity(sentences[0], unigram_counts, bigram_counts, len(unique_words), k=1.0)"
      ],
      "metadata": {
        "id": "35IrivOQFIt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity_value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMXhAKpwFc_B",
        "outputId": "f42dd252-e25a-455a-a7fe-4e790d6e2976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.8039657955522013"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def suggest_a_word(previous_tokens, n_gram_counts, n_plus1_gram_counts, vocabulary, k=1.0, start_with=None):\n",
        "    \n",
        "    n = len(list(n_gram_counts.keys())[0]) \n",
        "    previous_n_gram = previous_tokens[-n:]\n",
        "    probabilities = estimate_probabilities(previous_n_gram,n_gram_counts, n_plus1_gram_counts,vocabulary, k=k)\n",
        "    suggestion = None\n",
        "    max_prob = 0\n",
        "    \n",
        "    for word, prob in probabilities.items():\n",
        "        if start_with != None and not word.startswith(start_with):\n",
        "            continue\n",
        "        if prob > max_prob:\n",
        "            suggestion = word\n",
        "            max_prob = prob\n",
        "    return suggestion, max_prob"
      ],
      "metadata": {
        "id": "bh_kPWq9Fend"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [['i', 'like', 'a', 'cat'],\n",
        "             ['this', 'dog', 'is', 'like', 'a', 'cat']]\n",
        "\n",
        "previous_tokens = [\"i\", \"like\"]\n",
        "tmp_suggest1 = suggest_a_word(previous_tokens, unigram_counts, bigram_counts, unique_words, k=1.0)\n",
        "print(f\"The previous words are 'i like',\\n\\tand the suggested word is `{tmp_suggest1[0]}` with a probability of {tmp_suggest1[1]:.4f}\")\n",
        "\n",
        "print()\n",
        "# test your code when setting the starts_with\n",
        "tmp_starts_with = 'c'\n",
        "tmp_suggest2 = suggest_a_word(previous_tokens, unigram_counts, bigram_counts, unique_words, k=1.0, start_with=tmp_starts_with)\n",
        "print(f\"The previous words are 'i like', the suggestion must start with `{tmp_starts_with}`\\n\\tand the suggested word is `{tmp_suggest2[0]}` with a probability of {tmp_suggest2[1]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPoHIP8fJeBP",
        "outputId": "4072eef9-3a66-44e0-80cf-38d6ac146f3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The previous words are 'i like',\n",
            "\tand the suggested word is `a` with a probability of 0.2727\n",
            "\n",
            "The previous words are 'i like', the suggestion must start with `c`\n",
            "\tand the suggested word is `cat` with a probability of 0.0909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_suggestions(previous_tokens, n, sentences, k=1.0, start_with=None):\n",
        "\n",
        "    vocabulary = list(set(sentences[0] + sentences[1]))\n",
        "    n_gram_counts_list = []\n",
        "\n",
        "    for i in range(1, n):\n",
        "      n_model_counts = creat_n_grams(sentences, i)\n",
        "      n_gram_counts_list.append(n_model_counts)\n",
        "\n",
        "    model_counts = len(n_gram_counts_list)\n",
        "    suggestions = []\n",
        "\n",
        "    for i in range(model_counts-1):\n",
        "        n_gram_counts = n_gram_counts_list[i]\n",
        "        n_plus1_gram_counts = n_gram_counts_list[i+1]\n",
        "        suggestion = suggest_a_word(previous_tokens, n_gram_counts,n_plus1_gram_counts, vocabulary, k, start_with)\n",
        "        suggestions.append(suggestion)\n",
        "        \n",
        "    return suggestions"
      ],
      "metadata": {
        "id": "TeWADDPqJl69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 5\n",
        "\n",
        "sentences = [['i', 'like', 'a', 'cat'],\n",
        "             ['this', 'dog', 'is', 'like', 'a', 'cat']]\n",
        "\n",
        "previous_tokens = [\"i\", \"like\"]\n",
        "tmp_suggest = get_suggestions(previous_tokens, n, sentences, k=1.0)\n",
        "\n",
        "print(f\"The previous words are '{' '.join(previous_tokens)}', the suggestions are:\")\n",
        "display(tmp_suggest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "p2Q0aB2nKrqQ",
        "outputId": "4d4c466d-2dce-4857-86e4-c31cefc78fff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The previous words are 'i like', the suggestions are:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[('a', 0.2727272727272727), ('a', 0.2), ('like', 0.1111111111111111)]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previous_tokens = [\"i\", \"am\", 'to']\n",
        "tmp_suggest = get_suggestions(previous_tokens, n, sentences, k=1.0)\n",
        "\n",
        "print(f\"The previous words are '{' '.join(previous_tokens)}', the suggestions are:\")\n",
        "display(tmp_suggest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "RaWTFoVIK1WD",
        "outputId": "9ed814a4-694b-41d7-a0b4-50fa7ef2e5d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The previous words are 'i am to', the suggestions are:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[('like', 0.1111111111111111),\n",
              " ('like', 0.1111111111111111),\n",
              " ('like', 0.1111111111111111)]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = 3\n",
        "previous_tokens = [\"hey\", \"how\", \"are\", \"you\"]\n",
        "\n",
        "tmp_suggest = get_suggestions(previous_tokens, n, sentences, k=1.0)\n",
        "\n",
        "print(f\"The previous words are '{' '.join(previous_tokens)}', the suggestions are:\")\n",
        "display(tmp_suggest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "w7kshGvXNCAC",
        "outputId": "5993a334-a6e4-4113-cc8c-4033a58adb31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The previous words are 'hey how are you', the suggestions are:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[('like', 0.1111111111111111)]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gUdP-AWkNgBz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}