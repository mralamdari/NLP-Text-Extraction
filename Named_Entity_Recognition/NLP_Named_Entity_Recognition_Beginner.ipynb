{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-Named-Entity-Recognition-Beginner.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNo57MhuW+QUs07PLwCvZoy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mr-alamdari/NLP-Named-Entity-Recognition-Beginner/blob/main/NLP_Named_Entity_Recognition_Beginner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KDm7aWsbXZMC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import nltk\n",
        "import numpy\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install trax\n",
        "import trax\n",
        "from trax import layers as tl\n",
        "from trax.supervised import training\n",
        "from trax.fastmath import numpy as fastnp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ua4Ld72AbLHR",
        "outputId": "2af3e85e-c760-42de-f982-b095e52ab188"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting trax\n",
            "  Downloading trax-1.4.1-py2.py3-none-any.whl (637 kB)\n",
            "\u001b[K     |████████████████████████████████| 637 kB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jax in /usr/local/lib/python3.7/dist-packages (from trax) (0.3.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from trax) (1.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from trax) (1.4.1)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.7/dist-packages (from trax) (0.3.2+cuda11.cudnn805)\n",
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.8.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 42.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from trax) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from trax) (1.21.6)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from trax) (0.5.0)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from trax) (0.17.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from trax) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from trax) (4.0.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from trax) (5.4.8)\n",
            "Collecting funcsigs\n",
            "  Downloading funcsigs-1.0.2-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym->trax) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->trax) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->trax) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jax->trax) (4.1.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax->trax) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib->trax) (2.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->trax) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->trax) (3.0.8)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->trax) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->trax) (0.11.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (2.3)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (0.1.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (2.23.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (1.1.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (0.3.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (4.64.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (1.7.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (21.4.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (3.17.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->trax) (5.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets->trax) (2021.10.8)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->tensorflow-datasets->trax) (3.8.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets->trax) (1.56.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text->trax) (0.12.0)\n",
            "Requirement already satisfied: tensorflow<2.9,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text->trax) (2.8.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text->trax) (3.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text->trax) (13.0.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 53.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text->trax) (1.1.2)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text->trax) (2.8.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text->trax) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text->trax) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text->trax) (1.14.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text->trax) (1.44.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text->trax) (0.24.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text->trax) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text->trax) (57.4.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text->trax) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.9,>=2.8.0->tensorflow-text->trax) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.9,>=2.8.0->tensorflow-text->trax) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text->trax) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text->trax) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text->trax) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text->trax) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text->trax) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text->trax) (1.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text->trax) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text->trax) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text->trax) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text->trax) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text->trax) (4.11.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text->trax) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text->trax) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly, tensorflow-text, funcsigs, trax\n",
            "Successfully installed funcsigs-1.0.2 tensorflow-text-2.8.2 tf-estimator-nightly-2.8.0.dev2021122109 trax-1.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_generator(batch_size, x, y, pad, shuffle=False, verbose=False):\n",
        "    num_lines = len(x)\n",
        "    lines_index = [*range(num_lines)]\n",
        "    if shuffle:\n",
        "        numpy.random.shuffle(lines_index)\n",
        "    \n",
        "    index = 0 \n",
        "    while True:\n",
        "        buffer_x = [0] * batch_size \n",
        "        buffer_y = [0] * batch_size \n",
        "                \n",
        "        for i in range(batch_size):\n",
        "            if index >= num_lines:\n",
        "                index = 0\n",
        "                if shuffle:\n",
        "                    numpy.random.shuffle(lines_index)\n",
        "            \n",
        "            buffer_x[i] = x[lines_index[index]]\n",
        "            buffer_y[i] = y[lines_index[index]]\n",
        "            lenx = len(x[lines_index[index]])    \n",
        "            if lenx > max_len:\n",
        "                max_len = lenx                   \n",
        "             \n",
        "            index += 1\n",
        "        X = numpy.full((batch_size, max_len), pad)\n",
        "        Y = numpy.full((batch_size, max_len), pad)\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            x_i = buffer_x[i]\n",
        "            y_i = buffer_y[i]\n",
        "            for j in range(len(x_i)):\n",
        "                X[i, j] = x_i[j]\n",
        "                Y[i, j] = y_i[j]\n",
        "\n",
        "        if verbose: print(\"index=\", index)\n",
        "        yield((X,Y))"
      ],
      "metadata": {
        "id": "OcbDXf1QbNAc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def NER(tags, vocab_size=35181, d_model=50):\n",
        "    model = tl.Serial(\n",
        "      tl.Embedding(vocab_size, d_model), \n",
        "      tl.LSTM(d_model), \n",
        "      tl.Dense(len(tags)), \n",
        "      tl.LogSoftmax())\n",
        "    return model"
      ],
      "metadata": {
        "id": "jPKtT_z6hGVQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trax.supervised import training\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_generator = trax.supervised.inputs.add_loss_weights(\n",
        "    data_generator(batch_size, t_sentences, t_labels, vocab['<PAD>'], True),\n",
        "    id_to_mask=vocab['<PAD>'])\n",
        "\n",
        "eval_generator = trax.supervised.inputs.add_loss_weights(\n",
        "    data_generator(batch_size, v_sentences, v_labels, vocab['<PAD>'], True),\n",
        "    id_to_mask=vocab['<PAD>'])"
      ],
      "metadata": {
        "id": "V814Sjh2hKKL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(NER, train_generator, eval_generator, train_steps=1, output_dir='model'):\n",
        "    train_task = training.TrainTask(\n",
        "      train_generator,\n",
        "      loss_layer = tl.CrossEntropyLoss(),\n",
        "      optimizer = trax.optimizers.Adam(0.01))\n",
        "\n",
        "    eval_task = training.EvalTask(\n",
        "      labeled_data = eval_generator,\n",
        "      metrics = [tl.CrossEntropyLoss(), tl.Accuracy()],\n",
        "      n_eval_batches = 10)\n",
        "\n",
        "    training_loop = training.Loop(NER, train_task, eval_task = eval_task, output_dir = output_dir)\n",
        "\n",
        "   \n",
        "    training_loop.run(n_steps = train_steps)\n",
        "    return training_loop"
      ],
      "metadata": {
        "id": "sR5yI8s2htr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NER()\n",
        "model.init(trax.shapes.ShapeDtype((1, 1), dtype=np.int32))\n",
        "\n",
        "model.init_from_file('model.pkl.gz', weights_only=True)"
      ],
      "metadata": {
        "id": "B0mwxM9SijBh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = next(data_generator(len(test_sentences), test_sentences, test_labels, vocab['<PAD>']))"
      ],
      "metadata": {
        "id": "dYV2388zjFlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(pred, labels, pad):\n",
        "\n",
        "    outputs = numpy.argmax(pred, axis=2)\n",
        "    print(\"outputs shape:\", outputs.shape)\n",
        "\n",
        "    mask = labels != pad\n",
        "    print(\"mask shape:\", mask.shape, \"mask[0][20:30]:\", mask[0][20:30])\n",
        "    accuracy = numpy.sum(outputs == labels) / float(numpy.sum(mask))\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "xr_v2VsMixxK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = evaluate(model(x), y, vocab['<PAD>'])\n",
        "print(\"accuracy: \", accuracy)"
      ],
      "metadata": {
        "id": "CriF4u9ojDa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(sentence, model, vocab, tag_map):\n",
        "    s = [vocab[token] if token in vocab else vocab['UNK'] for token in sentence.split(' ')]\n",
        "    batch_data = np.ones((1, len(s)))\n",
        "    batch_data[0][:] = s\n",
        "    sentence = np.array(batch_data).astype(int)\n",
        "    output = model(sentence)\n",
        "    outputs = np.argmax(output, axis=2)\n",
        "    labels = list(tag_map.keys())\n",
        "    pred = []\n",
        "    for i in range(len(outputs[0])):\n",
        "        idx = outputs[0][i] \n",
        "        pred_label = labels[idx]\n",
        "        pred.append(pred_label)\n",
        "    return pred"
      ],
      "metadata": {
        "id": "wvjklwO4jaz9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Peter Navarro, the White House director of trade and manufacturing policy of U.S, said in an interview on Sunday morning that the White House was working to prepare for the possibility of a second wave of the coronavirus in the fall, though he said it wouldn’t necessarily come\"\n",
        "s = [vocab[token] if token in vocab else vocab['UNK'] for token in sentence.split(' ')]\n",
        "predictions = predict(sentence, model, vocab, tag_map)\n",
        "for x,y in zip(sentence.split(' '), predictions):\n",
        "    if y != 'O':\n",
        "        print(x,y)"
      ],
      "metadata": {
        "id": "aFbOgQ_TjfGH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}