{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-Sequence-Models-Beginner.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LNuQsXN63D_v"
      ],
      "authorship_tag": "ABX9TyPVfCMyvf2VJ87Yh7UqpVLs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mr-alamdari/NLP-Sequence-Models-Beginner/blob/main/NLP_Sequence_Models_Beginner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x0W9RKAVwSLZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import numpy\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U trax\n",
        "\n",
        "import trax\n",
        "\n",
        "import trax.fastmath.numpy as np\n",
        "\n",
        "from trax import layers as tl"
      ],
      "metadata": {
        "id": "uEwRNzEV2Ngn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef039752-19f7-477d-b43a-e4464b5c66fc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 637 kB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 50.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 53.7 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Practices**"
      ],
      "metadata": {
        "id": "LNuQsXN63D_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array(325)"
      ],
      "metadata": {
        "id": "6luyOIVn26zu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a994175-dcae-41e0-d374-0a88208b1270"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gjI-PK9B30Ft",
        "outputId": "c4f5795c-27f6-4403-a0cd-20b091270f25"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DeviceArray(325, dtype=int32, weak_type=True)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dylyy-re37yA",
        "outputId": "349537e3-1cb0-44ad-bb12-3f10ce8df16c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "jaxlib.xla_extension.DeviceArray"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x):\n",
        "  return 3 * x**2 - 32"
      ],
      "metadata": {
        "id": "4K48Dkpu39Et"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_a = f(a)\n",
        "d_a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FjMFcbd4KIl",
        "outputId": "5cbc462f-1d16-4704-b72c-abbfbda99a0f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(316843, dtype=int32, weak_type=True)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grad_f = trax.fastmath.grad(fun=f)"
      ],
      "metadata": {
        "id": "sBBER4nA4LZJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(grad_f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTb9EVLJ4Qyo",
        "outputId": "35b77f7b-e4c6-407f-f554-ec5586d2c595"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "function"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tweet_to_tensor(tweet, vocab_dict, unk_token='__UNK__', verbose=False):\n",
        "\n",
        "    word_list = process_tweet(tweet)\n",
        "    tensor_l = []\n",
        "    unk_ID = vocab_dict[unk_token]\n",
        "\n",
        "    for word in word_list:\n",
        "        word_ID = vocab_dict[word] if word in vocab_dict else unk_ID\n",
        "        tensor_l.append(word_ID) \n",
        "    \n",
        "    return tensor_l"
      ],
      "metadata": {
        "id": "8BWLHvyW4jgO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer(object):\n",
        "    def __init__(self):\n",
        "        self.weights = None\n",
        "\n",
        "    def init(self, input_signature, random_key):\n",
        "        self.init_weights_and_state(input_signature, random_key)\n",
        "        return self.weights\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)"
      ],
      "metadata": {
        "id": "FJOVqiZGOMiv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Relu(Layer):\n",
        "    def forward(self, x):\n",
        "        return np.maximum(x,0)"
      ],
      "metadata": {
        "id": "a0MXBVfTBehd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dense(Layer):\n",
        "\n",
        "    def __init__(self, n_units, init_stdev=0.1):\n",
        "        \n",
        "        self._n_units = n_units\n",
        "        self._init_stdev = init_stdev\n",
        "\n",
        "    def forward(self, x):\n",
        "        dense = np.dot(x, self.weights) \n",
        "        return dense\n",
        "\n",
        "    def init_weights_and_state(self, input_signature, random_key):\n",
        "        input_shape = input_signature.shape\n",
        "        w = self._init_stdev * trax.fastmath.random.normal(key = random_key, shape = (input_shape[-1], self._n_units))\n",
        "        self.weights = w\n",
        "        return self.weights"
      ],
      "metadata": {
        "id": "3OSjwW8wOny5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_embed = np.array([[1,2,3], [4,5,6]])\n",
        "\n",
        "display(np.mean(tmp_embed,axis=0))\n",
        "\n",
        "display(np.mean(tmp_embed,axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wtGgjaX_O0l8",
        "outputId": "da481e31-135c-4eae-be82-58a5c9323c18"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DeviceArray([2.5, 3.5, 4.5], dtype=float32)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DeviceArray([2., 5.], dtype=float32)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classifier(vocab, embedding_dim=256, output_dim=2, mode='train'):\n",
        "    vocab_size=len(vocab)\n",
        "    embed_layer = tl.Embedding(vocab_size=vocab_size, d_feature=embedding_dim)\n",
        "    \n",
        "    mean_layer = tl.Mean(axis=1)\n",
        "    \n",
        "    dense_output_layer = tl.Dense(n_units = output_dim)\n",
        "\n",
        "    log_softmax_layer = tl.LogSoftmax()\n",
        "    \n",
        "    model = tl.Serial(\n",
        "      embed_layer,\n",
        "      mean_layer,\n",
        "      dense_output_layer,\n",
        "      log_softmax_layer\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "pNE0XrytPE39"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trax.supervised import training\n",
        "\n",
        "def train_model(classifier, train_task, eval_task, n_steps, output_dir):\n",
        "    training_loop = training.Loop(\n",
        "                                classifier, # The learning model\n",
        "                                train_task, # The training task\n",
        "                                eval_task = eval_task, # The evaluation task\n",
        "                                output_dir = output_dir) # The output directory\n",
        "\n",
        "    training_loop.run(n_steps = n_steps)\n",
        "\n",
        "    return training_loop"
      ],
      "metadata": {
        "id": "ctgGCH56PfWq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_accuracy(preds, y, y_weights):\n",
        "\n",
        "    is_pos =  preds[:, 1] > preds[:, 0] \n",
        "    is_pos_int = is_pos.astype(np.int32)\n",
        "    correct = is_pos_int == y\n",
        "    sum_weights = np.sum(y_weights)\n",
        "    correct_float = correct.astype(np.float32)\n",
        "    weighted_correct_float = correct_float * y_weights\n",
        "    weighted_num_correct = np.sum(weighted_correct_float)\n",
        "    accuracy = weighted_num_correct / sum_weights\n",
        "    return accuracy, weighted_num_correct, sum_weights"
      ],
      "metadata": {
        "id": "zCnOfHrAPp2v"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(generator, model):\n",
        "    accuracy = 0.\n",
        "    total_num_correct = 0\n",
        "    total_num_pred = 0\n",
        "    for batch in generator: \n",
        "        inputs = batch[0]\n",
        "        targets = batch[1]\n",
        "        example_weight = batch[2]\n",
        "        pred = model(inputs)\n",
        "        batch_accuracy, batch_num_correct, batch_num_pred = compute_accuracy(pred, targets, example_weight)\n",
        "        total_num_correct += batch_num_correct\n",
        "        total_num_pred += batch_num_pred\n",
        "    accuracy = total_num_correct / total_num_pred\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "cnXFrem6QKR9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, Vocab, sentence):\n",
        "    inputs = np.array(tweet_to_tensor(sentence, vocab_dict=Vocab))\n",
        "    \n",
        "    inputs = inputs[None, :]  \n",
        "    \n",
        "    preds_probs = model(inputs)\n",
        "    \n",
        "    preds = int(preds_probs[0, 1] > preds_probs[0, 0])\n",
        "    \n",
        "    sentiment = \"negative\"\n",
        "    if preds == 1:\n",
        "        sentiment = 'positive'\n",
        "\n",
        "    return preds, sentiment"
      ],
      "metadata": {
        "id": "MIjhU65vQTy9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jl82WYN_QlRS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#N-Grams"
      ],
      "metadata": {
        "id": "-C85dZLc3NZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/amanjeetsahu/Natural-Language-Processing-Specialization/master/Natural%20Language%20Processing%20with%20Sequence%20Models/Week%202/shakespeare.png"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7perUho3QTo",
        "outputId": "d56c000b-3e21-4fa8-ddcc-fcb7bc6a6a0b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-21 13:14:07--  https://raw.githubusercontent.com/amanjeetsahu/Natural-Language-Processing-Specialization/master/Natural%20Language%20Processing%20with%20Sequence%20Models/Week%202/shakespeare.png\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1713575 (1.6M) [image/png]\n",
            "Saving to: ‘shakespeare.png’\n",
            "\n",
            "shakespeare.png     100%[===================>]   1.63M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-04-21 13:14:07 (28.8 MB/s) - ‘shakespeare.png’ saved [1713575/1713575]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/amanjeetsahu/Natural-Language-Processing-Specialization/master/Natural%20Language%20Processing%20with%20Sequence%20Models/Week%202/data/1kinghenryiv.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWiA0ls43xEv",
        "outputId": "e24dd174-a2fb-4068-a9e0-351650cc751e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-21 13:14:07--  https://raw.githubusercontent.com/amanjeetsahu/Natural-Language-Processing-Specialization/master/Natural%20Language%20Processing%20with%20Sequence%20Models/Week%202/data/1kinghenryiv.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 145002 (142K) [text/plain]\n",
            "Saving to: ‘1kinghenryiv.txt’\n",
            "\n",
            "1kinghenryiv.txt    100%[===================>] 141.60K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-04-21 13:14:08 (6.28 MB/s) - ‘1kinghenryiv.txt’ saved [145002/145002]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines = []\n",
        "with open('1kinghenryiv.txt', 'r') as files:\n",
        "  for line in files:\n",
        "      pure_line = line.strip()\n",
        "      if pure_line:\n",
        "          lines.append(pure_line)"
      ],
      "metadata": {
        "id": "bPugQJSz6Lgq"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines[0: 20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUgsTODZjMuW",
        "outputId": "517430d4-3b7d-42c2-c7b1-0f4e7b82923b"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1 KING HENRY IV',\n",
              " 'DRAMATIS PERSONAE',\n",
              " 'KING HENRY\\tthe Fourth. (KING HENRY IV:)',\n",
              " 'HENRY,',\n",
              " 'Prince of Wales\\t(PRINCE HENRY:)\\t|',\n",
              " '| sons of the King',\n",
              " 'JOHN of Lancaster\\t(LANCASTER:)\\t|',\n",
              " 'WESTMORELAND:',\n",
              " 'SIR WALTER BLUNT:',\n",
              " 'THOMAS PERCY\\tEarl of Worcester. (EARL OF WORCESTER:)',\n",
              " 'HENRY PERCY\\tEarl of Northumberland. (NORTHUMBERLAND:)',\n",
              " 'HENRY PERCY\\tsurnamed HOTSPUR, his son. (HOTSPUR:)',\n",
              " 'EDMUND MORTIMER\\tEarl of March. (MORTIMER:)',\n",
              " 'RICHARD SCROOP\\tArchbishop of York. (ARCHBISHOP OF YORK:)',\n",
              " 'ARCHIBALD\\tEarl of Douglas. (DOUGLAS:)',\n",
              " 'OWEN GLENDOWER:',\n",
              " 'SIR RICHARD VERNON\\t(VERNON:)',\n",
              " 'SIR JOHN FALSTAFF\\t(FALSTAFF:)',\n",
              " 'SIR MICHAEL\\ta friend to the Archbishop of York.',\n",
              " 'POINS:']"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ord('M'), ord('r'), ord(' '), ord('A'), ord('l'), ord('a'), ord('m'), ord('d'), ord('a'), ord('r'), ord('i')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rez21NojO77",
        "outputId": "da447c7d-0b47-4614-aad9-81e06d389b00"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(77, 114, 32, 65, 108, 97, 109, 100, 97, 114, 105)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "line2Tensor = lambda line, EoSentence='1': [ord(l) for l in line] + [ord(EoSentence)]"
      ],
      "metadata": {
        "id": "mzxaPPTilZNX"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_line = 'Mr Alamdari'\n",
        "line2Tensor(temp_line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-DzZRkXmUqO",
        "outputId": "48a6dea8-029b-44d0-9e2b-5986f7b5f4fa"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[77, 114, 32, 65, 108, 97, 109, 100, 97, 114, 105, 49]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_generator(lines, batch_size=2, max_length=10, shuffle=True):\n",
        "  n = len(lines)\n",
        "  lines_index = [*range(n)]\n",
        "  if shuffle:\n",
        "    numpy.random.shuffle(lines_index)\n",
        "\n",
        "  current_batch = []\n",
        "  index = 0\n",
        "  while True:\n",
        "    if index >= n:\n",
        "      index = 0\n",
        "      if shuffle:\n",
        "        numpy.random.shuffle(lines_index)\n",
        "    line = lines[index]\n",
        "\n",
        "    if len(line) < max_length:\n",
        "      current_batch.append(line)\n",
        "    index += 1\n",
        "\n",
        "    if len(current_batch) == batch_size:\n",
        "      batch = []\n",
        "      mask = []\n",
        "      for l in current_batch:\n",
        "        tensor = line2Tensor(l)\n",
        "        pad = [0] * (max_length - len(tensor))\n",
        "        padded_tensor = tensor + pad\n",
        "        batch.append(padded_tensor)\n",
        "        masked_tensor = numpy.sign(padded_tensor)\n",
        "        masked_tensor[masked_tensor == -1] = 0\n",
        "        mask.append(masked_tensor)\n",
        "      \n",
        "      yield np.array(batch), np.array(mask)\n",
        "\n",
        "      current_batch = []"
      ],
      "metadata": {
        "id": "lCwNhlnPmZEN"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_lines = ['12345678901','123456789','234567890','345678901']\n",
        "data_gen = data_generator(temp_lines, batch_size=2, max_length=10, shuffle=False)"
      ],
      "metadata": {
        "id": "Gu_qn9C-4RGC"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(data_gen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nqqv7h24VoU",
        "outputId": "7d34552d-20fb-451a-8f9e-5c9855da1cd2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(DeviceArray([[49, 50, 51, 52, 53, 54, 55, 56, 57, 49],\n",
              "              [50, 51, 52, 53, 54, 55, 56, 57, 48, 49]], dtype=int32),\n",
              " DeviceArray([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(data_gen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j00jSgwF4mzu",
        "outputId": "ed3667c7-c110-4016-9df6-a1812580d0d8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(DeviceArray([[51, 52, 53, 54, 55, 56, 57, 48, 49, 49],\n",
              "              [49, 50, 51, 52, 53, 54, 55, 56, 57, 49]], dtype=int32),\n",
              " DeviceArray([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "count=12\n",
        "infinite_data_generator = itertools.cycle(data_generator(lines, batch_size=2, max_length=10))\n",
        "twelve_lines = [next(infinite_data_generator) for _ in range(count)]"
      ],
      "metadata": {
        "id": "2DizSy0_55Fk"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twelve_lines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3I7rOgM70z5",
        "outputId": "bfb23941-1d9a-4e42-8499-1c934a6d8e24"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(DeviceArray([[49, 50, 51, 52, 53, 54, 55, 56, 57, 49],\n",
              "               [50, 51, 52, 53, 54, 55, 56, 57, 48, 49]], dtype=int32),\n",
              "  DeviceArray([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)),\n",
              " (DeviceArray([[51, 52, 53, 54, 55, 56, 57, 48, 49, 49],\n",
              "               [49, 50, 51, 52, 53, 54, 55, 56, 57, 49]], dtype=int32),\n",
              "  DeviceArray([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)),\n",
              " (DeviceArray([[50, 51, 52, 53, 54, 55, 56, 57, 48, 49],\n",
              "               [51, 52, 53, 54, 55, 56, 57, 48, 49, 49]], dtype=int32),\n",
              "  DeviceArray([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)),\n",
              " (DeviceArray([[49, 50, 51, 52, 53, 54, 55, 56, 57, 49],\n",
              "               [50, 51, 52, 53, 54, 55, 56, 57, 48, 49]], dtype=int32),\n",
              "  DeviceArray([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)),\n",
              " (DeviceArray([[51, 52, 53, 54, 55, 56, 57, 48, 49, 49],\n",
              "               [49, 50, 51, 52, 53, 54, 55, 56, 57, 49]], dtype=int32),\n",
              "  DeviceArray([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)),\n",
              " (DeviceArray([[50, 51, 52, 53, 54, 55, 56, 57, 48, 49],\n",
              "               [51, 52, 53, 54, 55, 56, 57, 48, 49, 49]], dtype=int32),\n",
              "  DeviceArray([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)),\n",
              " (DeviceArray([[49, 50, 51, 52, 53, 54, 55, 56, 57, 49],\n",
              "               [50, 51, 52, 53, 54, 55, 56, 57, 48, 49]], dtype=int32),\n",
              "  DeviceArray([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)),\n",
              " (DeviceArray([[51, 52, 53, 54, 55, 56, 57, 48, 49, 49],\n",
              "               [49, 50, 51, 52, 53, 54, 55, 56, 57, 49]], dtype=int32),\n",
              "  DeviceArray([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)),\n",
              " (DeviceArray([[50, 51, 52, 53, 54, 55, 56, 57, 48, 49],\n",
              "               [51, 52, 53, 54, 55, 56, 57, 48, 49, 49]], dtype=int32),\n",
              "  DeviceArray([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)),\n",
              " (DeviceArray([[49, 50, 51, 52, 53, 54, 55, 56, 57, 49],\n",
              "               [50, 51, 52, 53, 54, 55, 56, 57, 48, 49]], dtype=int32),\n",
              "  DeviceArray([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)),\n",
              " (DeviceArray([[51, 52, 53, 54, 55, 56, 57, 48, 49, 49],\n",
              "               [49, 50, 51, 52, 53, 54, 55, 56, 57, 49]], dtype=int32),\n",
              "  DeviceArray([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)),\n",
              " (DeviceArray([[50, 51, 52, 53, 54, 55, 56, 57, 48, 49],\n",
              "               [51, 52, 53, 54, 55, 56, 57, 48, 49, 49]], dtype=int32),\n",
              "  DeviceArray([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "               [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32))]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GRU Model"
      ],
      "metadata": {
        "id": "De-be1lq8nEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GRULM(vocab_size=256, d_model=512, n_layers=2, mode='train'):\n",
        "  model = tl.Serial(\n",
        "      tl.ShiftRight(mode=mode),\n",
        "      tl.Embedding(vocab_size=vocab_size, d_feature=d_model),\n",
        "      [tl.GRU(n_units=d_model) for _ in range(n_layers)],\n",
        "      tl.Dense(n_units=vocab_size),\n",
        "      tl.LogSoftmax()\n",
        "  )\n",
        "  return model"
      ],
      "metadata": {
        "id": "5BVSQ_No8KeN"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GRULM()"
      ],
      "metadata": {
        "id": "Z1gjrFjnXoT-"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GMjGz5hX-or",
        "outputId": "765917ec-eb0f-4bc1-d19a-dc49a4d567fe"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Serial[\n",
            "  Serial[\n",
            "    ShiftRight(1)\n",
            "  ]\n",
            "  Embedding_256_512\n",
            "  GRU_512\n",
            "  GRU_512\n",
            "  Dense_256\n",
            "  LogSoftmax\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "max_length = 64"
      ],
      "metadata": {
        "id": "ob42-YsUYE1N"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def number_of_used_lines(lines, max_length):\n",
        "  return numpy.sum(numpy.array([1 for l in lines if len(l)<=max_length]))"
      ],
      "metadata": {
        "id": "PysGrIyiYQSI"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(lines), number_of_used_lines(lines, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTA0Ki48Yr-h",
        "outputId": "9dee7fb1-9515-4ef4-98c8-7a85a22cddf7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_lines = lines[:1000] \n",
        "lines = lines[1000:] "
      ],
      "metadata": {
        "id": "3y8Wx-0yeRF-"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Train data: {len(lines)}, Evaluation data: {len(eval_lines)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J76KjUyNelMH",
        "outputId": "64d6ae46-522c-4a6a-de40-f312389dab62"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data: 2298, Evaluation data: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from trax.supervised import training\n",
        "\n",
        "def train_val(model, data_gen, batch_size=32, max_length=64, lines=lines, eval_lines=eval_lines, n_steps=1, output_dir='/content/model_outputs/'):\n",
        "  train_data_generated = data_gen(batch_size=32, max_length=64, lines=lines)\n",
        "  infinite_train_data_generated = itertools.cycle(train_data_generated)\n",
        "\n",
        "  eval_data_generated = data_gen(batch_size=32, max_length=64, lines=lines)\n",
        "  infinite_eval_data_generated = itertools.cycle(eval_data_generated)\n",
        "\n",
        "  train_task = training.TrainTask(labeled_data=infinite_train_data_generated,\n",
        "                                  loss_layer = tl.CrossEntropyLoss(),\n",
        "                                  optimizer = trax.optimizers.Adam(5e-4))\n",
        "\n",
        "  eval_task = training.EvalTask(labeled_data=infinite_eval_data_generated,\n",
        "                                metrics=[tl.CrossEntropyLoss(), tl.Accuracy()],\n",
        "                                n_eval_batches=3)\n",
        "  \n",
        "  training_loop = training.Loop(model, \n",
        "                                train_task,\n",
        "                                eval_task=eval_task,\n",
        "                                output_dir=output_dir)\n",
        "  \n",
        "  training_loop.run(n_steps=n_steps)\n",
        "  return training_loop"
      ],
      "metadata": {
        "id": "7unGBhhyZ0CX"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loop = train_val(GRULM(), data_generator)"
      ],
      "metadata": {
        "id": "ujUK1JIfZ595"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(preds, target):\n",
        "  total_log_ppx = np.sum(preds * tl.one_hot(target, preds.shape[-1]), axis=-1)\n",
        "  non_pad = 1.0 - np.equal(target, 0)\n",
        "  ppx = total_log_ppx * non_pad\n",
        "  log_ppx = np.sum(ppx) / np.sum(non_pad)\n",
        "  return -log_ppx"
      ],
      "metadata": {
        "id": "QR7ESPGwfDlo"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GRULM()\n",
        "model.init_from_file('model.pkl.gz')\n",
        "batch = next(data_generator(batch_size, max_length, lines, shuffle=False))\n",
        "preds = model(batch[0])\n",
        "log_ppx = test_model(preds, batch[0])"
      ],
      "metadata": {
        "id": "Dl4oDMrCiNsG"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gumbel_sample(log_probs, temperature=1.0):\n",
        "    u = numpy.randon.uniform(low=1e-6, high=1.0 - 1e-6, size=log_probs.shape)\n",
        "    g = -np.log(-np.log(u))\n",
        "    return np.argmax(log_probs + g * temperature, axis=-1)"
      ],
      "metadata": {
        "id": "nDl8bB_Fj-uw"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(num_chars, prefix):\n",
        "    inp = [ord(c) for c in prefix]\n",
        "    result = [c for c in prefix]\n",
        "    max_len = len(prefix) + num_chars\n",
        "    for _ in range(num_chars):\n",
        "        cur_inp = np.array(inp + [0] * (max_len - len(inp)))\n",
        "        outp = model(cur_inp[None, :])  \n",
        "        next_char = gumbel_sample(outp[0, len(inp)])\n",
        "        inp += [int(next_char)]\n",
        "       \n",
        "        if inp[-1] == 1:\n",
        "            break  \n",
        "        result.append(chr(int(next_char)))\n",
        "    \n",
        "    return \"\".join(result)\n",
        "\n",
        "print(predict(32, \"\"))"
      ],
      "metadata": {
        "id": "blxaE2nWjqMP"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "U1eMq8h5kz45"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}